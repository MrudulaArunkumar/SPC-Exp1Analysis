---
title: "Exp8 Analysis"
author: "Mrudula Arunkumar"
date: "`r format(Sys.time(), '%d %B,%Y')`"
output:
  html_document:
    theme: readable
    highlight: breezedark
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 7
    fig_height: 4
    code_folding: hide
  pdf_document:
    toc: yes
---

**This document contains the result memo of Experiment 8 aimed to disentangle the awareness/insight factor and the retrieval effects. We found from out previous experiment *Exp7 Analysis.rmd* that overshadowing was present but this seemed to be driven by the nudges that participants received as those with awareness showed the effect. While looking at it from an SRB level and previous occurrence, it did not moderate the interaction. But this is also tricky because the design of the previous experiment had test and learn trials intermixed that also visually looked different. So with this experiment, it builds on from the success of overshadowing in the last experiment by using only learn-like displays but testing overshadowing by manipulating the presence/absence of the salient or nonsalient distractor, similar to how it looked in the guessing learn trials of the previous experiment. So this will use the terms "MultipleD" to indicate the compound learn trials display and "SingleD" to mark the ones where one of the distractors is present. There will also be no guessing trials in between, and participants will only be asked at the end of the experiment. Given that they all look similar this experiment work can disentangle the role of inisght and provide more scope to explore retrieval effects.**

```{r loadlibs, include=FALSE, message=FALSE}

library(tidyverse)
library(plyr)
library(ez) #for anova
library(schoRsch) #anova output
library(knitr) #rmarkdown output
library(pander) #tables in rmarkdown
library(rmarkdown)
library(reshape2)
library(here) #replace setwd for easier reproducible code
library(ggpubr)
library(lme4)
library(nlme)
library(lmerTest)
library(car)
library(ggdist)
library(Rmisc) 

#set_here() #done only once and amde sure that that .here file is saved int eh same directory as the script for it to work successfully

Exp8data <- read.csv(here("Data", "Exp8_fulldataset.csv"))
Exp8data$participant <- as.factor(Exp8data$participant)

##creating a command that does the opposite of %in% -> useful in filter or select functions
`%notin%` <- Negate(`%in%`)

```

Below is the overview of the experiment trials.

```{r image, echo=FALSE, out.width="100%", fig.align = 'center'}
knitr::include_graphics(here("Figures","Trial Count.png"))
knitr::include_graphics(here("Figures","Experiment flow.png"))
```

The trials are divided as SingleDistractor (SingleD) and MultipleDistractor (MultipleD). SingleD is where either the **salient** or the **nonsalient** distractor is presented along with a *random* letter chosen as the other distractor. MultipleD is the compound display where participants learn the association for **both salient and nonsalient** letters.

1. The MultipleD trials with both nonsalient and salient letters: for 'left' and 'right' responses

```{r trials, echo=FALSE, out.width="49%", fig.show = "hold"}

knitr::include_graphics(here("Figures","GX learn.png"))
knitr::include_graphics(here("Figures","VL learn.png"))

```

2. Salient SingleD trials

```{r salsingled, echo = FALSE,out.width='49%', fig.show='hold'}

knitr::include_graphics(here("Figures","G salient.png"))
knitr::include_graphics(here("Figures","V salient.png"))
```

3. NonSalient SingleD trials

```{r nsalsingled, echo=FALSE, out.width='49%', fig.show='hold'}

knitr::include_graphics(here("Figures","X nonsalient.png"))
knitr::include_graphics(here("Figures","L nonsalient.png"))
```


# Data preparation and cleaning
-   Removing unnecessary columns generated by psychopy
-   Preparing the RT trial, by eliminating the square brackets and splitting it in cases where two keys were registered.
-   Creating a column for Accuracy and Error Rate
-   adding a Bonus column that computes the points received by each participant

> 3 participants had to be removed due to high Error Rate, so N = 67 instead of 70. 

```{r cleaning, include=FALSE, message=FALSE, warning=FALSE}
#removing unnecessary columns
Exp8data <- Exp8data %>%
  select(-X,-ConsentKey.keys,-ConsentKey.rt,-Begin.keys,-Begin.rt,-checkresp.corr,-checkresp.keys,-checkresp.rt,-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisN,-Attention.thisIndex,-Attention.ran,-AttnQuestion,-AttnAnswer,-NextStep.keys,-NextStep.rt,-InstRep.ran,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,-InstRep.thisIndex,-PracProceed.keys,-PracProceed.rt,-Prac_loop.thisRepN,-Prac_loop.thisTrialN,-Prac_loop.thisN,-Prac_loop.thisIndex,-Prac_loop.ran,-Exp_proceed.keys,-Exp_proceed.rt,-PracRepeat.ran,-PracRepeat.thisRepN,-PracRepeat.thisN,-PracRepeat.thisIndex,-PracRepeat.thisTrialN,-brkContinue.keys,-PauseResp.keys,-PauseResp.rt, -CA_Proceed.keys,-CA_Proceed.rt,-headstartLearn.thisRepN,-headstartLearn.thisTrialN,-headstartLearn.thisIndex,-headstartLearn.thisN,-headstartLearn.ran,-ExpTrials.ran,-ExpTrials.thisIndex,-CA_trials.thisRepN,-CA_trials.thisN,-CA_trials.thisIndex,-CA_trials.thisTrialN,-CA_trials.ran,-AwareQ_loop.thisRepN,-AwareQ_loop.ran,-AwareQ_loop.thisIndex,-AwareQ_loop.thisTrialN,-todebrief.keys,-Finalend.keys)

#adding a block variable by splitting it manually using trial number
Exp8data <- Exp8data %>%
  mutate(BlockCount = ifelse(ExpTrials.thisN <= 104, 1,
                             ifelse(ExpTrials.thisN <=208 & ExpTrials.thisN > 104,2,
                                    ifelse(ExpTrials.thisN <= 312 & ExpTrials.thisN > 208,3,
                                           ifelse(ExpTrials.thisN <= 415 & ExpTrials.thisN > 312,4,NA)))))


#adjusting RT
Exp8data <- separate(Exp8data, col = TargetResp.rt, into = c("RT_Trials", "RT_secondary"), sep = ',')
Exp8data$RT_Trials <- Exp8data$RT_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp8data$RT_Trials)
Exp8data$RT_Trials <- 1000*(Exp8data$RT_Trials)


#creating a Bonus column, for prolific
Exp8data$Bonus <- as.integer(Exp8data$Bonus)

#creating an aggregate File with bonus for prolific onus update
Exp8Bonus <- aggregate(data = Exp8data, Bonus~PROLIFIC_ID, sum)
Exp8Bonus$Perf <- na.omit(Exp8data$Performance)


###creating a separate df with the contingency awareness related questionnaire
Exp8_CA <- Exp8data%>%
 filter(Target == "?" | str_detect(AwareQ, "Press"))

#remove the unrelated RT rows, like the ones involved in break and intro screens.
Exp8data <- Exp8data%>%drop_na(RT_Trials)

#creating an accuracy column
Exp8data$ACC_trials <- Exp8data$TargetResp.corr
#column for error Rate
Exp8data$ErrorRate <- 1 - Exp8data$ACC_trials

#average error and RT data to cross check with the performance evaluation
Exp8ER <- aggregate(data = Exp8data,ErrorRate~PROLIFIC_ID,mean)
Exp8RT <- aggregate(data = Exp8data,RT_Trials~PROLIFIC_ID,mean)

#filter erroneous participants
Exp8data <- Exp8data %>%
  filter(participant %notin% c(20,70,12))
```

## Descriptives

Summary of the overall Reaction Time, accuracy and Error Rate

```{r descriptives, echo=FALSE,results='asis'}

pander(summary(Exp8data$Age),style = 'rmarkdown', caption = "Age")

pander(summary(Exp8data$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp8data$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

pander(round(table(Exp8data$ACC_trials)/nrow(Exp8data)*100, digits = 3), style = 'rmarkdown', caption = "Percentage of errors")
```

Upon implementing the exclusion criteria

-   Outliers (1.5x above third quartile) --> used for the analysis
-   Farouts (3x above third quartile)
-   very Fast RTs, less than 200ms

```{r exclusions, echo=FALSE, results='asis'}
#removing the erroneous RTs
Exp8data$RT_Trials[Exp8data$ACC_trials==0] <- NA


#creating function to remove the outliers and farouts. This function computes the outlier and farout value
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts and applying the function at the individual level
Exp8data <- ddply(Exp8data, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp8data$RT_ifo <- Exp8data$RT_Trials #ifo is individual farouts
Exp8data$RT_io <- Exp8data$RT_Trials  #io is individual outliers

#removing the RTs that are above outlier/farout RT and very fast RTs
Exp8data$RT_ifo[Exp8data$RT_ifo > Exp8data$Farouts|Exp8data$RT_ifo < 200] <- NA

Exp8data$RT_io[Exp8data$RT_io > Exp8data$Outlier|Exp8data$RT_io < 200] <- NA

#mean of the RTs -- for outlier exclusion and farout exclusion
pander(summary(Exp8data$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp8data$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")

```

# ANALYSES


## 1. Validity Manipulation check - all trials

> There is no validity effect seen in RTs. $t = 1.4, p = .16$

```{r valcheck, message=FALSE,results='asis'}
##creating an aggregate to check for validity effect
#Exp8multiple_agg <- aggregate(data = Exp8data, RT_ifo~participant+Validity,mean)

## ONLY USING THE OUTLIER EXCLUSED RTs####

Exp8multiple_agg_o <- aggregate(data = Exp8data, RT_io~participant+Validity,mean)
Exp8multiple_agg_ER <- aggregate(data = Exp8data, ErrorRate~participant+Validity, mean)
#sum(is.na(Exp8data$RT_io))

#for outliers
pander(aggregate(data = Exp8multiple_agg_o, RT_io~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, outliers excluded")

# t test between valid and invalid RTs
pander((t.test(data = Exp8multiple_agg_o, RT_io~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials-excluding outliers")

#for ErrorRate
pander(aggregate(data = Exp8multiple_agg_ER, ErrorRate~Validity,mean), style = "rmarkdown", caption = "Table containing means of ER for valid and invalid learn trials, outliers excluded")
# t test between valid and invalid ERs
pander((t.test(data = Exp8multiple_agg_ER, ErrorRate~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials-Error rate")

# plot describing the RTs and ERs of overall valid and invalid trials 
valmain <- ggplot(Exp8multiple_agg_o, aes(x=Validity, y=RT_io))+
    geom_line(aes(group = 1, color = "cadetblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Validity,color = "cadetblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(500,600))+
  scale_color_manual(values = c("deepskyblue4"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean of valid and invalid trials")
valmain
#ggsave(filename = here("Figures","Validity_main.png"),valmain)



valmainER <- ggplot(Exp8multiple_agg_ER, aes(x=Validity, y=ErrorRate))+
    geom_line(aes(group = 1, color = "cadetblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Validity,color = "cadetblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(0, 0.15))+
  scale_color_manual(values = c("deepskyblue4"))+
  theme_classic()+ylab("Error Rate")+ggtitle("Mean of valid and invalid trials")
valmainER
#ggsave(filename = here("Figures","Validity_main_ER.png"),valmainER)

```

## 2. Saliency Manipulation Check

This analysis checks whether the saliency manipulation worked by comparing the RT between trials where the number appeared in salient letters position vs non salient letter's position.

> There is no significant difference between trials where the target appeared at the salient letter position vs non salient letter's position ($p = 0.12$), with the salient letter being 15ms faster than nonsalient letter's position.



```{r salcheck, message=FALSE,results='asis'}
# Exp8SalCheck <- aggregate(data = Exp8data, RT_ifo~participant+Saliency, subset = (Block == "SalMC"), mean)
#saliency manipulation check for RTs
Exp8SalCheck_o <- aggregate(data = Exp8data, RT_io~participant+Saliency, subset = (Block == "SalMC"), mean)

pander(aggregate(data = Exp8SalCheck_o, RT_io~Saliency,mean), style = "rmarkdown", caption = "Table containing means of salient and nonsalient, outliers excluded")

#saliency manipulation check for ERs
Exp8SalCheck_ER <- aggregate(data = Exp8data, ErrorRate~participant+Saliency, subset = (Block == "SalMC"), mean)

pander(aggregate(data = Exp8SalCheck_ER, ErrorRate~Saliency,mean), style = "rmarkdown", caption = "Table containing means of salient and nonsalient, Error Rate")

#checking the difference between the saliency conditions
pander(t.test(RT_io~Saliency, data = Exp8SalCheck_o,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation, outliers")

pander(t.test(ErrorRate~Saliency, data = Exp8SalCheck_ER,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation, ErrorRate")

#plot of saliency manipulation check for RTs
salmain <- ggplot(Exp8SalCheck_o, aes(x=Saliency, y=RT_io, color = "firebrick3"))+
    geom_line(aes(group = 1),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Saliency),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(600,700))+
  scale_color_manual(values = c("firebrick3"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean RT of trial with target behind \n salient vs non salient distractor")+theme(text = element_text(size = 20))
salmain

#ggsave(filename = here("Figures","Saliency_main.png"),salmain)
```

## 3. Interaction of Validity x Saliency in test trials

This analysis is the main one concerning overshadowing.

1.  Farouts: Not analyzed further as outliers prove to be a better exclusion criteria

```{r interactionfo, eval=FALSE, warning=FALSE, message=FALSE}

## aggregating the data for farouts and for outliers

Exp8agg_fo <- aggregate(data = Exp8data, RT_ifo~participant+Validity+Saliency, subset = (Condition == "SingleD"), mean)


anova_VS_fo <- ezANOVA(data = Exp8agg_fo,
                       dv = RT_ifo,
                       wid = participant,
                       within = .(Validity, Saliency),type = 3,
                       detailed = TRUE)
panderOptions('table.split.table',300) #for more refined presentation of pander anova output
pander(anova_VS_fo, style = "rmarkdown", caption = "ANOVA for test trials with Validity and Saliency as factors",split.table = Inf, missing = NA)

# aov_VS_fo <- aov(RT_ifo~(Validity*Saliency)+Error(participant/(Validity*Saliency)), data = Exp8agg_fo)
# summary(aov_VS_fo)

ezPlot(data = Exp8agg_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity, Saliency),
       split = Validity, x = Saliency, do_bars = FALSE)+theme_classic()+
  ggtitle("Interaction effect between saliency and validity for test trials")



#stdInteraction_fo <- ggplot(Exp8agg_fo, aes(x=Saliency, y=RT_ifo,color = Validity))+
#    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
#    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+ylim(500,600)+
#  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
#  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")

#ggsave(filename = here("Figures","interaction_fo.png"),stdInteraction_fo)

mean_valEffect_fo <- ezStats(data = Exp8agg_fo,
        dv = RT_ifo,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)

pander(mean_valEffect_fo, style = "rmarkdown", title = "Validity effect(invalid-valid) for salient and non salient letters in test trials(farouts)")


pander(t.test(data = Exp8agg_fo, RT_ifo~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, farouts")
```

2.  Outliers:

The validity effect is not significant, $F = 0.01, p = 0.63$, however the main effect of saliency is *almost* significant at $ p = 0.053$. The interaction between validity and saliency is also *almost* significant with $F = 3.28, p = .074$. One thing to note in this scenario is that the total number of valid and invalid trials has a 90:10 contingency ratio, which leads to less data points for invalid trials and all the more likely to miss more since invalid trials are more error-prone leading to NA RTs.

```{r interactiono, warning=FALSE, message=FALSE, results='asis'}
##for outliers
  
Exp8agg_o <- aggregate(data = Exp8data, RT_io~participant+Validity+Saliency, subset = (Condition == "SingleD"), mean)

#ANOVA
anova_VS_o <- ezANOVA(data = Exp8agg_o,
                       dv = RT_io,
                       wid = participant,
                       within = .(Validity, Saliency),
                       detailed = TRUE)

panderOptions('table.split.table',300)#for refined presentation of pander anova output
pander(anova_VS_o, style = "rmarkdown", title = "ANOVA for test trials(w/o outliers) with Validity and Saliency as factors",split.table = Inf, missing = NA)



stdInteraction_o <- ggplot(Exp8agg_o, aes(x=Validity, y=RT_io,color = Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean")+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("steelblue3","red3"))+coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")+theme(text = element_text(size = 20))
stdInteraction_o
#ggsave(filename = here("Figures","interaction_o.png"),stdInteraction_o,width = 6,height = 4)

```

Here is a closer look at the effects, showing the mean difference between valid and invalid in each condition. The effects are not significant for both the salient and nonsalient trials.

```{r meandiff, echo = FALSE, warning=FALSE, message=FALSE, results='asis'}

# to compure paired differences CI to use for the error bars 
meanSalVal2 <- summarySEwithin(Exp8agg_o, measurevar="RT_io", withinvars=c("Validity"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

t<-t.test(RT_io ~ Validity, data =Exp8agg_o, paired=TRUE, alternative="two.sided" )
t_out(t, d.corr=F)
t$sdpd <- t$stderr*sqrt(67)

tns<-t.test(RT_io ~ Validity, data =Exp8agg_o, subset
=(Saliency=="NonSalient"), paired=TRUE, alternative="two.sided" )
t_out(tns, d.corr=F)
tns$sdpd <- tns$stderr*sqrt(67)

#Mean difference between validity to get the validity effect
mean_valEffect_o <- ezStats(data = Exp8agg_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)


pander(mean_valEffect_o, style = "rmarkdown", caption =  "Validity effect(invalid-valid) for salient and non salient test trials(outliers)")


# significance of the validity effect
pander(t.test(data = Exp8agg_o, RT_io~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, outliers")
# # 
# # 
 pander(t.test(data = Exp8agg_o, RT_io~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for nonsalient trials, outliers")

##for outliers

salvalmean <- ggplot(meanSalVal2, aes(x=Saliency, y=RT_io,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = RT_io - ci, ymax = RT_io + ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(500,600))+
  theme_classic()+ylab("ReactionTime (in ms)")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20))
salvalmean

#ggsave(filename = here("Figures","Barplot_salxval_RT.png"),salvalmean)

Valeffectplot <- ggplot(mean_valEffect_o, aes(x=Saliency, y=Mean, fill = "cornflowerblue"), show.legend = FALSE)+
    geom_bar(stat = "identity", show.legend = FALSE)+
  scale_fill_manual(values = c("dodgerblue4"))+ylab("Mean difference (invalid - valid)")+
  theme_classic()+ggtitle("Difference between valid and invalid trials")
Valeffectplot

#ggsave(filename = here("Figures","Valeffectplot_o.png"),Valeffectplot,width = 6, height = 4)

```

## 4. Error Rate

> Error Rate data show a huge significant main effect of Saliency $F = 18.5, p < .001$ and a large significant interaction of validity and Saliency, $F = 14.7, p < .001$

```{r Errorate, message=FALSE, warning=FALSE,results='asis'}

##aggregate file for Error Rate with Validity and Saliency
Exp8agg_ER <- aggregate(data = Exp8data,ErrorRate~participant+Validity+Saliency,subset = (Condition == "SingleD"),mean)


##ANOVA
anova_t_ER <- ezANOVA(data = Exp8agg_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials", split.table = "Inf", missing = NA)

# anova_out(anova_t_ER)

errorrateplot <-  ggplot(Exp8agg_ER, aes(x=Validity, y=ErrorRate,color =Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("steelblue3","firebrick3"))+coord_cartesian(ylim = c(0,0.15))+
  theme_classic()+ylab("Error Rate")+ggtitle("Interaction of Validity and Saliency with ErrorRate as DV")
errorrateplot
#ggsave(filename = here("Figures","ErrorRate.png"),errorrateplot,width=6,height = 4)

#to compute CI for Paired differences to use for the error bars
meanSalVal_ER2 <- summarySEwithin(Exp8agg_ER, measurevar="ErrorRate", withinvars=c("Saliency","Validity"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

salvalmean_ER <- ggplot(meanSalVal_ER2, aes(x=Saliency, y=ErrorRate
                                            ,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = ErrorRate- ci, ymax = ErrorRate + ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(0, 0.15))+
  theme_classic()+ylab("Error Rate")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20))
salvalmean_ER

#ggsave(filename = here("Figures","bargraph_ER_valxsal.png"),salvalmean_ER)

pander(t.test(data = Exp8agg_ER, ErrorRate~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, outliers")
# # 
# # 
pander(t.test(data = Exp8agg_ER, ErrorRate~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for nonsalient trials, outliers")


```

The plot also shows the expected pattern, wherein the salient SingleD trials show a larger difference in valid and invalid trials' performances compared to the nonsalient SingleD trials.

**Since the results are absent in RT but present in ER,it becomes interesting to investigate this effect using a combined score**

## 5. Inverse Efficiency scores and Balance Integration Score

1.  The Inverse Efficiency score ([Bruyer, R & Brysbaert, M., 2011](https://www.psychologicabelgica.com/articles/abstract/10.5334/pb-51-1-5/)) simply combines the RT and Error Rate into a single variable, $IES = RT/(1-ErrorRate)$

2.  The Balance Integration Score (Liesefeld & Jancyzk, 2019) is another form of combining RT and Error Rate but in contrast to the IES, the BIS standardizes the two variables and computes a single variable using this formula, $BIS = z(1-ErrorRate) - z(RT)$

This [research article](https://link.springer.com/article/10.3758/s13428-018-1076-x#Bib1) talks about these methods in depth

```{r faroutsies, include=FALSE}
## create a df that contains only the trials needed for analysis which are the singleD trials

Exp8test <- Exp8data %>%
  subset(Condition == "SingleD")
```

Outliers

1.  **with IES as Dependent variable**

> There is a significant interaction with validity and saliency and a main effect of saliency with a marginal significance for validity $F = 3.18, p = .07$

The ANOVA results along with the interaction plot are shown below. The mean difference graph is also presented to have a different visualization of the effects.

```{r outliersiesbis, echo = FALSE, warning=FALSE, message=FALSE,results='asis'}

###FOR OUTLIERS
# creating an aggregate with both the RT and ER to be able to compute the IES and BIS
Exp8agg_IES_o <- aggregate(Exp8test[,c("RT_io","ErrorRate","ACC_trials")], by = list(participant = Exp8test$participant,
                                                                       Validity = Exp8test$Validity,
                                                                       Saliency = Exp8test$Saliency), mean,na.rm = TRUE)

Exp8agg_IES_o$IES <- Exp8agg_IES_o$RT_io/(1-Exp8agg_IES_o$ErrorRate)
Exp8agg_IES_o$ZRT <- scale(Exp8agg_IES_o$RT_io)
Exp8agg_IES_o$ZPC <- scale(Exp8agg_IES_o$ACC_trials)
Exp8agg_IES_o$BIS <- Exp8agg_IES_o$ZPC - Exp8agg_IES_o$ZRT


pander(aggregate(data = Exp8agg_IES_o, IES~Validity+Saliency,mean))

##with IES
anova_t_IES_o <- ezANOVA(data = Exp8agg_IES_o,
        dv = IES,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_IES_o, style = 'rmarkdown', caption = "ANOVA results: using IES(outliers)", split.table = "Inf", missing = NA)

IESinterplot_o <- ggplot(Exp8agg_IES_o, aes(x=Validity, y=IES,color = Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("steelblue3","firebrick3"))+coord_cartesian(ylim = c(550,700))+
  theme_classic()+ylab("IES (in ms)")+ggtitle("Interaction of Validity and Saliency")
IESinterplot_o
#ggsave(filename = here("Figures","IESinterplot_o.png"),IESinterplot_o)

```


The plot below shows the mean difference in validity across saliency. Although in this case, both salient and nonsalient trials show a significant validity effect with salient ones having a larger effect

```{r IESplot, warning=FALSE, message=FALSE}
meanSalVal_IES2 <- summarySEwithin(Exp8agg_IES_o, measurevar="IES", withinvars=c("Saliency","Validity"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

meanSalVal_IES <- ezStats(data = Exp8agg_IES_o,
        dv = IES,
        wid = participant,
        within = .(Saliency,Validity))
meanSalVal_IES$SE <- meanSalVal_IES$SD/sqrt(meanSalVal_IES$N)

meanIES_o <- ezStats(data = Exp8agg_IES_o,
        dv = IES,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff = .(Validity),
        reverse_diff = TRUE)

pander(meanIES_o, style = "rmarkdown", caption = "Mean IES score validity effect")


salvalmeanIES <- ggplot(meanSalVal_IES2, aes(x=Saliency, y=IES,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = IES-ci, ymax = IES+ ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(550,750))+
  theme_classic()+ylab("IES (in ms)")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20)) 
salvalmeanIES

#ggsave(filename = here("Figures","Barplot_salxval_IES.png"),salvalmeanIES)

valeffectIES_o <- ggplot(data = meanIES_o, aes(x = Saliency, y = Mean, fill = "dodgerblue4"))+scale_fill_manual(values = c("dodgerblue4"))+
  geom_bar(stat = "identity")+
  theme_classic()+
  ylab("Validity Effect(invalid-valid trials) in ms")+theme(legend.position = "none")+
  ggtitle("Validity Effect (invalid - valid) across test trials (IES) averaged across participant")
valeffectIES_o
#ggsave(filename = here("Figures","valEffectwithIES_o.png"),valeffectIES_o)


```

2.  **with BIS as dependent variable**

> There is a significant saliency effect and a significant interaction between validity and saliency. Validity effect is still not significant.

The ANOVA and the interaction plot are shown below. *To be noted in the plot: The y axis is represented as a z score*. Higher the score --> better the performance.

```{r BIS, echo=FALSE, warning=FALSE, message=FALSE, results='asis'}
##with BIS
anova_t_BIS_o <- ezANOVA(data = Exp8agg_IES_o,
        dv = BIS,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_BIS_o, style = 'rmarkdown', caption = "ANOVA results: using BIS(outliers)", split.table = "Inf", missing = NA)


BISinterplot_o <- ggplot(Exp8agg_IES_o, aes(x=Saliency, y=BIS,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("BIS (z score difference)")+ggtitle("Interaction of Validity and Saliency")
BISinterplot_o
#ggsave(filename = here("Figures","BISinterplot_o.png"),BISinterplot_o)


```

The mean difference is also significant for IES and BIS in the salient condition *but also in the nonsalient* condition however it is reversed in the non salient condition.

1.  **IES**

```{r iesmean, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}

##outliers
pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp8agg_IES_o, IES~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

2.  **BIS**

```{r meanBIS, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}
##outliers
pander(t.test(data = Exp8agg_IES_o, BIS~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp8agg_IES_o, BIS~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

## 6. With Awareness

Here, we explore the role of insight and awareness and see if participants' ability to detect the contingencies play a role in a significant overshadowing effect. The Awareness was tested in two ways:

1.  via guessing trials that were presented at the end of the experiment, with a total of 8 in number, 4 per salient letter and 4 per nonsalient.

2.  Via a Questionnaire that was asked at the end of the experiment, after the trials. The questions are as follows.

    1. Did you have an impression that an even number appeared after a particular red letter? Press 'j' for yes and 'n' for no and 't' if you do not know. 
  
    2.  Did you have an impression that an odd number appeared after a particular red letter? Press 'j' for yes and 'n' for no and 't' if you do not know. 
  
    3. What response almost always followed a red "V"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.

    4. What response almost always followed a red "G"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.
  
    5. What response almost always followed "L"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.
  
    6. What response almost always followed "X"? Press the relevant response key ("e" or "u") on the keyboard or press "t" if you do not know.

### 1. Guessing trials

First some data preparation is done to examine the performance in the awareness guessing trials.

* Computing the accuracy total per salient(4) and nonsalient(4) conditions

* computing the total sum and mean accuracy

* marking participants who answered correctly for the salient letters in the guessing trials as a factor called **SalAware**. If 1, then they answered all salient trials accurately, if 0 then they had one or more errors

> 24 people answered all the salient distractor trials accurately

```{r CAguess, echo=FALSE, warning=FALSE, message=FALSE}
Exp8_CA <- Exp8_CA %>%
  select(-TargetResp_p.corr,-TargetResp_p.keys,-TargetResp_p.rt,-TargetResp.corr,-TargetResp.keys,-todebrief.rt,-Finalend.rt)
Exp8_CA$AwareResp.corr <- as.factor(Exp8_CA$AwareResp.corr)
Exp8_CA$AwareResp.keys <- as.character(Exp8_CA$AwareResp.keys)
Exp8_CA$Solution <- as.character(Exp8_CA$Solution)
Exp8_CA <- Exp8_CA %>%
  filter(participant %notin% c(20,70,12))
#two columns stating the total accuracy of guessing trials for salient and nonsalient
Exp8_CA$SalTotalAcc <- NA
Exp8_CA$NonSalTotalAcc <- NA

Exp8_CA <- Exp8_CA %>%
  mutate(SalTotalAcc = ifelse(Saliency == "Salient" & (CAResponse_2.corr == 1), 1, 0))

Exp8_CA <- Exp8_CA %>%
  mutate(NonSalTotalAcc = ifelse(Saliency == "NonSalient" & (CAResponse_2.corr == 1), 1, 0))


CA_Summary <- Exp8_CA %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(TotalAcc = sum(CAResponse_2.corr, na.rm = TRUE),
                   MeanAcc = mean(CAResponse_2.corr, na.rm = TRUE),
                  SalAcc = sum(SalTotalAcc, na.rm = TRUE),
                  NonSalAcc = sum(NonSalTotalAcc, na.rm = TRUE))


CA_Summary$MeanAcc <- 100*CA_Summary$MeanAcc

CA_Summary <- CA_Summary %>%
  mutate(Salaware = ifelse(SalAcc == 4, 1, 0))

CA_Summary$participant <- as.factor(CA_Summary$participant)
# 
# pander(table(CA_Summary$participant,CA_Summary$SalAcc),style = "rmarkdown", caption="Awareness scores for participants for salient and non salient stimuli")

```

These plots show the overall accuracy of the participants in the guessing trials.

The plot shows that in the Guess trials most participants seemed to be scoring better for the Salient trials compared to the non salient.

```{r CA plot, echo=FALSE, message=FALSE, warning=FALSE}

CAplot <- ggplot(CA_Summary, aes(x = Saliency))+
  geom_violin(aes(x= Saliency,y=TotalAcc,fill="skyblue3"),alpha = 0.5, width = .4)+
  geom_jitter(aes(x= Saliency, y = TotalAcc,color="dodgerblue3"))+
  stat_summary(aes(y = TotalAcc, group = Condition), fun.y=mean, geom="line", colour="midnightblue")+
#  geom_hline(aes(yintercept = mean(TotalAcc), group = Saliency))+
 scale_fill_manual(values = c("skyblue3"))+scale_color_manual(values = c("dodgerblue3"))+
  theme_classic()+theme(legend.position = "none")+
  ggtitle("Summary of Contingency Awareness scores \n split by Salient or non salient trial")
CAplot

pander(t.test(data = CA_Summary,TotalAcc~Saliency,paired = TRUE), style = "rmarkdown", caption = "t test for Accuracy rate between salient and nonsalient trials, outliers")
# # 

#ggsave(filename = here("Figures","GuessingAccuracy.png"),CAplot)

```

#### ANOVA with the guessing trials awareness as a continuous variable and a covariate



```{r anovaGuess, warning=FALSE, message=FALSE}
Exp8agg_GuessAware_o <- merge(Exp8agg_o, CA_Summary,by=c("participant"))
Exp8agg_GuessAware_o$SalAcc <- (Exp8agg_GuessAware_o$SalAcc/4)*100
anovaG_VS <- aov(data = Exp8agg_GuessAware_o, RT_io~Validity*Saliency*SalAcc)

pander(Anova(anovaG_VS, type = "III"), style = "rmarkdown", caption = "ANCOVA results with guessing accuracy (type 3 SS)")
summary(anovaG_VS)

Acccovar <- ggplot(Exp8agg_GuessAware_o, aes(x = SalAcc, y = RT_io,group = Validity))+
  geom_jitter(aes(x = SalAcc, y = RT_io, color = Validity))+stat_smooth(aes(x=SalAcc, y = RT_io, color=Validity),method = "loess")+scale_color_manual(values = c("dodgerblue4","cadetblue3"))+theme_classic()+xlab("Salient Guessing Trial Accuracy %")+ylab("Reaction Time in ms")
Acccovar
#ggsave(filename = here("Figures","AccCovariateRT.png"), Acccovar)

##For ErrorRate
Exp8agg_GuessAware_ER <- merge(Exp8agg_ER, CA_Summary,by=c("participant"))
Exp8agg_GuessAware_ER$SalAcc <- (Exp8agg_GuessAware_ER$SalAcc/4)*100
anovaG_VSer <- aov(data = Exp8agg_GuessAware_ER, ErrorRate~Validity*Saliency*SalAcc)

pander(Anova(anovaG_VSer, type = "III"), style = "rmarkdown", caption = "ANCOVA results with guessing accuracy (type 3 SS)")
summary(anovaG_VS)

AcccovarER <- ggplot(Exp8agg_GuessAware_ER, aes(x = SalAcc, y = ErrorRate,group = Validity))+
  geom_jitter(aes(x = SalAcc, y = ErrorRate, color = Validity))+stat_smooth(aes(x=SalAcc, y = ErrorRate, color=Validity),method = "loess")+scale_color_manual(values = c("dodgerblue4","cadetblue3"))+theme_classic()+xlab("Salient Guessing trial Accuracy %")+ylab("Error Rate")
AcccovarER

#ggsave(filename = here("Figures","AccCovariateER.png"), AcccovarER)

```


### 2. Awareness Questionnaire

Here, a summary dataframe is created only with the performances of the participants from the 6 questions mentioned above.


* The variable *SalQAcc* is created to check for which of the salient letter related questions did the participants answer accurately
  
  * The variable *TotalSalQAcc* tells what the total score of accuracy is for those salient related questions. 
  
* If participants answered both the salient letter related questions accuractely (*i.e., if TotalSalQAcc  = 2*) then *SalQAware* is created that denotes that the participants were aware at the questionnaire level.

> 30 people show awareness in terms of answering the salient questions accurately.

```{r awareprep, warning=FALSE, message=FALSE}
Exp8_CA$AwareResp.corr <- as.numeric(Exp8_CA$AwareResp.corr)

#creating a dataframe dealing with the performance of Awareness Questionnaire.
AwareQ <- aggregate(data = Exp8_CA, AwareResp.corr~participant+AwareQ_loop.thisN+AwareQ+AwareResp.keys+Solution,mean)
AwareQ$AccDicho <- ifelse(AwareQ$AwareResp.corr == 2,1,0)


AwareQ$SalQAcc <- ifelse(AwareQ$AwareQ_loop.thisN == "2" & AwareQ$AwareResp.corr == 2 | AwareQ$AwareQ_loop.thisN == "3" & AwareQ$AwareResp.corr== 2,1,0)

pander(table(AwareQ$AwareQ,AwareQ$AwareResp.corr), style = "rmarkdown", title = "Question number and the number of participants answering accurately (1) or not (0)")
# table(AwareQ_Summary$Dicho)

A_Summary <- AwareQ %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(TotalQAcc = sum(AccDicho, na.rm = TRUE),
                   MeanQAcc = mean(AccDicho, na.rm = TRUE),
                  TotalSalQAcc = sum(SalQAcc, na.rm=TRUE))


A_Summary$SalQAware <- ifelse(A_Summary$TotalSalQAcc == "2" ,1,0)
pander(table(A_Summary$SalQAware), style = "rmarkdown", caption = "Number of participants with awareness(1) in the salient funnelled questions from the questionnaire")
```

#### ANOVA with Awareness QUestions

```{r ancovaques, warning=FALSE, message=FALSE}
Exp8agg_QAware_o <- merge(Exp8agg_o, A_Summary,by=c("participant"))
Exp8agg_QAware_o$TotalSalQAcc <- (Exp8agg_QAware_o$TotalSalQAcc/2)*100
anovaQ_VS <- aov(data = Exp8agg_QAware_o, RT_io~Validity*Saliency*TotalSalQAcc)

pander(Anova(anovaQ_VS, type = "III"), style = "rmarkdown", caption = "RT: ANCOVA results with questionnaire accuracy (type 3 SS)")


QuesAcc <- ggplot(Exp8agg_QAware_o, aes(x = TotalSalQAcc, y = RT_io,group = Validity))+
  geom_jitter(aes(x = TotalSalQAcc, y = RT_io, color = Validity))+stat_smooth(aes(x=TotalSalQAcc, y = RT_io, color=Validity),method = "loess")+theme_classic()+scale_color_manual(values = c("dodgerblue4","cadetblue3"))+xlab("Salient distractor Question Accuracy %")+ylab("Reaction time in ms")
QuesAcc
table(Exp8agg_QAware_o$TotalSalQAcc)
#ggsave(filename = here("Figures","QUestionAcc_RT.png"),QuesAcc)
##For ErrorRate
Exp8agg_QAware_ER <- merge(Exp8agg_ER, A_Summary,by=c("participant"))
Exp8agg_QAware_ER$TotalSalQAcc <- (Exp8agg_QAware_ER$TotalSalQAcc/2)*100
anovaQ_VSer <- aov(data = Exp8agg_QAware_ER, ErrorRate~Validity*Saliency*TotalSalQAcc)

pander(Anova(anovaQ_VSer, type = "III"), style = "rmarkdown", caption = "ER: ANCOVA results with questionnaire accuracy (type 3 SS)")
summary(anovaQ_VSer)

QuesAccER <- ggplot(Exp8agg_QAware_ER, aes(x = TotalSalQAcc, y = ErrorRate,group = Validity))+
  geom_jitter(aes(x = TotalSalQAcc, y = ErrorRate, color = Validity))+stat_smooth(aes(x=TotalSalQAcc, y = ErrorRate, color=Validity),method = "loess")+theme_classic()+scale_color_manual(values = c("dodgerblue4","cadetblue3"))+xlab("Salient distractor Question Accuracy %")+ylab("Error Rate")
QuesAccER

#ggsave(filename = here("Figures","QUestionAcc_ER.png"),QuesAccER)
```


### 3. Combining both measures of awareness: guessing trials and questions

Now, let's focus only on the Salient guessing trials as well as questions. With the combined score of salient questions in both awareness guesisng and questionniare the total comes to 6 (4 guessing trials and 2 questions). The participants with a score more than or equal to 5 are labelled as **"Aware"** and the others are marked as **"Not Aware"**.



> 26 people are "aware" with combined accuracy score of 5 or more in the salient questions and guessing trials.

```{r bothaware, message=FALSE, warning=FALSE}

#if learnguess salient is high label those participants as learnAware. To be used to check if they correlate with the AwareQ responses of those participants

Bothaware <- merge(CA_Summary,A_Summary, by = "participant")

Bothaware$CombinedAcc <- Bothaware$TotalSalQAcc + Bothaware$SalAcc
Bothaware$SalAcc <- (Bothaware$SalAcc/4)*100
Bothaware$TotalSalQAcc <- (Bothaware$TotalSalQAcc/2)*100
Bothaware$CombinedAcc <- (Bothaware$CombinedAcc/6)*100
Bothaware <- Bothaware %>%
  mutate(AwarenessLevel = ifelse(CombinedAcc >=80, "Aware", "Not Aware"))
pander(table(Bothaware$AwarenessLevel),style = "rmarkdown", caption = "Participants who showed awareness at the salient level")



Exp8agg_A_o <- merge(Exp8agg_o, Bothaware, by = c("participant"))
Exp8agg_A_ER <- merge(Exp8agg_ER, Bothaware, by = c("participant"))
Exp8agg_A_IES <- merge(Exp8agg_IES_o, Bothaware, by = c("participant"))

```


#### Correlation between awareness at the questions and the guessing trials

```{r awarecorr, warning=FALSE, message=FALSE}
cor.test(Exp8agg_A_o$SalAcc, Exp8agg_A_o$TotalSalQAcc, method = "pearson")

correlACC <- ggplot(Exp8agg_A_o, aes(x = SalAcc, y = TotalSalQAcc))+
  geom_jitter(aes(x = SalAcc, y = TotalSalQAcc), color = "seagreen")+
  stat_smooth(method = "lm", color = "seagreen")+theme_classic()+xlab("Accuracy score in guessing trials")+ylab("Accuracy score in Questions")+ggtitle("Correlation between both tests of awareness")
correlACC

#ggsave(filename = here("Figures","CorrelACC.png"),correlACC)

```



#### ANOVA using AwarenessLevel as a factor


#### with RT

There is a borderline main effect of saliency $F = 3.82, p = .05$ and an almost significant interaction between saliency and validity $F = 3.93, p = 0.051$. However, there is a significant 3-way interaction with awareness and saliency and validity $F = 13.97, p < .001$ which was absent in Experiment 7. 

```{r awareanova, warning=FALSE, message=FALSE}

anova_VSA_o <- ezANOVA(data = Exp8agg_A_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        between = .(AwarenessLevel),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSA_o, style = 'rmarkdown', caption = "ANOVA with awareness (RT)",split.table = Inf, missing = NA)

awareInterG <- ggplot(Exp8agg_A_o, aes(x=Validity, y=RT_io,color = Saliency))+
    geom_line(aes(group = Saliency, linetype =Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("dodgerblue4","cadetblue3"))+facet_grid(.~AwarenessLevel, labeller = label_wrap_gen(width = 10))+coord_cartesian(ylim = c(500,600))+xlab("Validity")+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")+ theme(text = element_text(size = 20))
awareInterG


#ggsave(filename = here("Figures","InteractionwithBothawareness_RT.png"),awareInterG)
```


The plot shows the different interaction pattern per awareness condition. When participants show complete awareness both in the questionnaire as well guessing trials then it is the perfect pattern of larger validity effect for salient compared to nonsalient.This type of pattern is also seen among participants who showed awareness during the questionnaire but not so during the guessing trials. Strangely, a reverse patternw as observed in the participants with awareness in the guessing trials.

```{r meansaware, warning=FALSE, message=FALSE}
mean_valEffectA_o <- ezStats(data = Exp8agg_A_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        between = .(AwarenessLevel),
        reverse_diff = TRUE)

meanSalVal_A2 <- summarySEwithin(Exp8agg_A_o, measurevar="RT_io", withinvars=c("Saliency","Validity"),betweenvars = c("AwarenessLevel"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

salvalmeanAware <- ggplot(meanSalVal_A2, aes(x=Saliency, y=RT_io,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = RT_io - ci, ymax = RT_io + ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(500,650))+facet_grid(.~AwarenessLevel)+
  theme_classic()+ylab("Reaction Time (in ms)")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20)) 
salvalmeanAware
ggsave(filename = here("Figures","barplot with Awareness.png"), salvalmeanAware)
pander(mean_valEffectA_o, style = "rmarkdown", caption = "Validity Effect for salient and nonsalient distractors in all groups of awareness")

valeffectA <- ggplot(mean_valEffectA_o, aes(x=Saliency, y=Mean, fill = "cornflowerblue"), show.legend = FALSE)+
    geom_bar(stat = "identity", show.legend = FALSE)+
  scale_fill_manual(values = c("dodgerblue4"))+ylab("Mean difference (invalid - valid)")+facet_grid(.~AwarenessLevel)+
  theme_classic()+ggtitle("Difference between valid and invalid trials")
valeffectA

ggsave(filename = here("Figures","Valeffectbetween Awareness.png"), valeffectA)
```

#### with ER

There is a large main effect of saliency and an almost significant main effect of validity $F = 3.47, p = 0.06 $ and all the two-way interactions of saliency and validity with awareness are significant. The three-way interaction is significant as well. 


```{r awareErr, message=FALSE, warning=FALSE}

anova_VSAer_o <- ezANOVA(data = Exp8agg_A_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        between = .(AwarenessLevel),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSAer_o, style = "rmarkdown", caption = "ANOVA with awareness: ER",split.table = Inf, missing = NA)
```

The plot looks as expected for people with complete awareness and with people who are aware at the questionnaire level but not with guessing trials. However, in contrast to the RT data, the participants with awareness at theguessing but not the questions also show a similar, expected pattern but not as large.


```{r awareplotER, message=FALSE, warning=FALSE}


meanSalVal_erA2 <- summarySEwithin(Exp8agg_A_ER, measurevar="ErrorRate", withinvars=c("Saliency","Validity"),betweenvars = c("AwarenessLevel"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

salvalmeanAwareer <- ggplot(meanSalVal_erA2, aes(x=Saliency, y=ErrorRate,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = ErrorRate - ci, ymax = ErrorRate + ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(0,0.25))+facet_grid(.~AwarenessLevel)+
  theme_classic()+ylab("Error rate")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20)) 
salvalmeanAwareer
ggsave(filename = here("Figures","barplot with Awareness_ER.png"), salvalmeanAwareer)


pander(mean_valEffectA_o, style = "rmarkdown", caption = "Validity Effect for salient and nonsalient distractors in all groups of awareness")
awareInterG_ER <- ggplot(Exp8agg_A_ER, aes(x=Validity, y=ErrorRate,color = Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("dodgerblue4","cadetblue3"))+facet_grid(.~AwarenessLevel, labeller = label_wrap_gen(width = 10))+xlab("Saliency")+
  theme_classic()+ylab("Error Rate")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")+ theme(legend.text = element_text(size = 15), legend.title  = element_text(size = 15), axis.text.x = element_text(size = 15), axis.text.y = element_text(size = 15),axis.title.x = element_text(size = 15),axis.title.y = element_text(size = 15),strip.text.x = element_text(size = 15))
awareInterG_ER

#ggsave(filename = here("Figures","InteractionwAwareness_ER.png"), awareInterG_ER)

```
#### with IES

These results are similar to the one seen wit ER.

```{r awreIES, warning=FALSE, message=FALSE}
anova_VSAIES_o <- ezANOVA(data = Exp8agg_A_IES,
        dv =IES,
        wid = participant,
        within = .(Saliency,Validity),
        between = .(AwarenessLevel),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSAIES_o,style = "rmarkdown", caption = "ANOVA with awareness: IES",split.table = Inf, missing = NA)



awareInterG_IES <- ggplot(Exp8agg_A_IES, aes(x=Validity, y=IES,color = Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("steelblue3","firebrick3"))+facet_grid(.~AwarenessLevel, labeller = label_wrap_gen(width = 10))+xlab("Saliency")+
  theme_classic()+ylab("IES (in ms)")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareInterG_IES

#ggsave(filename = here("Figures","InteractionwAwareness_IES.png"), awareInterG_IES)


meanSalVal_iesA2 <- summarySEwithin(Exp8agg_A_IES, measurevar="IES", withinvars=c("Saliency","Validity"),betweenvars = c("AwarenessLevel"),
                                 idvar="participant", na.rm=FALSE, conf.interval=.95)

salvalmeanAwareies <- ggplot(meanSalVal_iesA2, aes(x=Saliency, y=IES,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = IES - ci, ymax = IES + ci),width = .1, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(500,900))+facet_grid(.~AwarenessLevel)+
  theme_classic()+ylab("IES (in ms)")+xlab("Single Distractor's Saliency")+theme(text = element_text(size = 20)) 
salvalmeanAwareies

ggsave(filename = here("Figures","barplot with Awareness_IES.png"), salvalmeanAwareies)
pander(mean_valEffectA_o, style = "rmarkdown", caption = "Validity Effect for salient and nonsalient distractors in all groups of awareness")



```


```{r ttestaware, eval=FALSE}

# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "CompleteAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with full awareness")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "GuessAwareness Not Question"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only trials)")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "QuestionAwareness Not guess"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only question)")
# 
# pander(t.test(data = Exp8agg_A_o, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "NoAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with no awareness")
```



# MULTI LEVEL MODELLING -- 

check memo - Exp8_MLM-report.html

```{r include=FALSE}

#compute new vars####
  #compute new numeric var for validity effect
  Exp8data$val <-ifelse(Exp8data$Validity=="valid",1,-1)
  table(Exp8data$val, Exp8data$Validity)

  table(Exp8data$val, Exp8data$Condition)

  #numeric var for saliency
  Exp8data$sal<-ifelse(Exp8data$Saliency=="Salient",1,
                       ifelse(Exp8data$Saliency=="NonSalient", -1, NA))

  table(Exp8data$Saliency, Exp8data$sal)


```


## 7. Previous Occurence Analysis (Distance & Response Type)

Computing a new column that contains the last time/number of trials ago the previous occurrence occurred.

Eg., Distance = 1 means that the last time the distractor appeared was one trial ago, Distance = 5 means the last time the Distractor appeared was 5 trials ago.

The conditions used to satisfy this last occurrence are:

-   Whether last trial was test/learn (*Since the trials are intermixed*)
-   Whether the Salient **OR** Non salient Distractor appeared.
-   The last occurrence was a trial that was answered correctly

```{r prevocc, eval = FALSE, message=FALSE, warning=FALSE}

Exp8data <- Exp8data%>%select(Condition, SalD,NSalD,Saliency,Validity, everything())

###first is to find out the trials where the previous occurence wa the immediate previous one
Exp8data$Distance <- NA
Exp8data <- Exp8data%>%select(Distance,ACC_trials,everything())
Exp8data <- Exp8data%>%
  mutate(Distance = ifelse((lag(Condition,1)=="SingleD" | lag(Condition,1) == "MultipleD")&
              (lag(SalD,1)== SalD|lag(NSalD,1)==NSalD) &
                            lag(participant,1)==participant &
                            lag(ACC_trials,1)== 1, 1, Distance))

#The number of immediate previous occurences
pander(table(Exp8data$Distance), style = 'rmarkdown', caption = "Table showing the number of immediate previous occurence")

## Now to look at other distances of the last occurrence beyond the immediately preceding one
lagvalue <- 2:20

for(j in lagvalue){
  Exp8data <- Exp8data %>%
    mutate(Distance = ifelse((lag(Condition,j)=="MultipleD"|lag(Condition,j)=="SingleD") &                     (lag(SalD,j)==SalD|lag(NSalD,j)==NSalD) & lag(participant,j)==participant & lag(ACC_trials,j)== 1 & is.na(Distance)==TRUE, j, Distance))
}

pander(table(Exp8data$Distance), style = 'rmarkdown', caption = "Table showing the number of total previous occurences and how far each of them are")


##code trial type for previous distance: learn trial = 1, test trial=2
  Exp8data$Distance_type<-NA
  Exp8data <- Exp8data%>%
    mutate(Distance_type = ifelse(Distance==1 & lag(Condition,1)=="MultipleD",1,
                                  ifelse(Distance==1 &lag(Condition,1)=="SingleD", 2, Distance_type)))

  table(Exp8data$Distance_type)
  Exp8data <- Exp8data%>%
    select(Distance, Distance_type, Condition, everything())

  #code for nonimmediate distances
  for (j in lagvalue){
    Exp8data <- Exp8data%>%
      mutate(Distance_type = ifelse(Distance==j & lag(Condition,j)=="MultipleD", 1,
                                    ifelse(Distance==j &lag(Condition,j)=="SingleD", 2, Distance_type)))
    }
```



### Previous Response

Coding what the previous Response was, whether it was the same or different. This variable is defined as Response Type, which has two factors: Response Change(RC) and Response Repetition (RR)

*To be noted: This does not equate to validity* because the SRB trials can have the combination of invalid prime and invalid probe --\> Response Repetition which is confounded by Validity. So every valid probe can have both the Response Type factors based on whether the prime is valid or invalid

```{r disttype, eval=FALSE, message=FALSE, warning=FALSE}

Exp8data$ResponseRel <- NA


Exp8data <- Exp8data %>%
  mutate(ResponseRel = ifelse((lag(Condition,1)=="MultipleD" | lag(Condition,1)=="SingleD") & lag(participant,1)==participant & lag(CorrectAnswer,1)== CorrectAnswer & is.na(ResponseRel)==TRUE, "RR", ifelse((lag(Condition,1)=="MultipleD"|lag(Condition,1)=="SingleD") & lag(participant,1)==participant & lag(CorrectAnswer,1)!= CorrectAnswer & is.na(ResponseRel)==TRUE, "RC", ResponseRel)))


pander(table(Exp8data$ResponseRel),style = 'rmarkdown', caption = "Total number of RRs and RCs")

Exp8data <- Exp8data%>%select(ResponseRel, everything())

#write.csv(file = here("Data","DataforMLM.csv"),Exp8data)


```
These factors are then used for the multi level modelling analysis


```{r}
Exp8data <- merge(Exp8data,Bothaware, by = "participant")

#splitting the dataframe to aware and without awareness
Exp8Aware <- Exp8data %>%
  filter(AwarenessLevel == "Aware")
#write.csv(file = here("Data","Exp8_withawareness.csv"), Exp8Aware)

Exp8UnAware <- Exp8data %>%
  filter(AwarenessLevel == "Not Aware")
#write.csv(file = here("Data","Exp8_withoutawareness.csv"),Exp8UnAware)
```


# Exploratory Analyses

This exploratory analysis involves the factors of contingency awareness from the guessing trials and the awareness questionnaire responses

## 1. Block Analysis


The plot shows that after te first block the participants tend to pick up on the learning and show a pattern of larger validity effect for salient trials. But there is also a strong reversal of pattern for nonsalient trials.

```{r block, warning=FALSE, message=FALSE}

Exp8agg_B_o <- aggregate(data = Exp8data, RT_io~participant+Validity+Saliency+BlockCount+AwarenessLevel, subset = (Condition == "SingleD"), mean)

blockRT.wide <- Exp8agg_B_o
blockRT.wide$AwarenessLevel <- as.factor(blockRT.wide$AwarenessLevel)
blockRT.wide$index <- paste(blockRT.wide$Saliency, blockRT.wide$Validity, blockRT.wide$BlockCount, sep = ".")
blockRT.wide <- dcast(participant + AwarenessLevel ~ index, data = blockRT.wide, value.var = "RT_io")

outmatrix <- as.matrix(blockRT.wide[, c(3:18)])

myModel <- lm(outmatrix ~ 1 + AwarenessLevel, data = blockRT.wide)

      myFactors <- data.frame(Saliency = c("Nonsalient", "Nonsalient", "Nonsalient", "Nonsalient","Nonsalient","Nonsalient","Nonsalient","Nonsalient","Salient","Salient","Salient","Salient","Salient","Salient","Salient","Salient"),
                              
                            Validity = c("invalid","invalid","invalid","invalid","valid","valid","valid","valid"),
                            Blockcount = c(1,2,3,4))
      myFactors$Saliency<-factor(myFactors$Saliency)
      myFactors$Validity<-factor(myFactors$Validity)
      myFactors$Blockcount <- factor(myFactors$Blockcount)
      contrasts(myFactors$Saliency)<-c(-1,1)
      contrasts(myFactors$Validity)<-c(-1,1)
      contrasts(blockRT.wide$AwarenessLevel)<-c(-1,1)
      
      
      summary(Anova(mod = myModel, 
                  idata = myFactors, 
                  idesign = ~ Saliency *Validity* Blockcount, 
                  type = "III"), 
            multivariate = F, 
            univariate = T)
    
# ###Anova with Blocks ## EZANOVA error
# anova_t_block <- ezANOVA(data = Exp8agg_B_o,
#         dv = RT_io,
#         wid = participant,
#         within = .(Saliency,Validity,BlockCount),
#         between = .(AwarenessLevel),
#         detailed = TRUE)
# panderOptions('table.split.table',300)
# pander(anova_t_block, style = 'rmarkdown', caption = "ANOVA results: with BlockCount", split.table = "Inf", missing = NA)


interBlock <- ggplot(Exp8agg_B_o, aes(x=Validity, y=RT_io,color = Saliency))+
    geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_color_manual(values = c("steelblue3","firebrick3"))+facet_grid(AwarenessLevel~BlockCount)+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency per Block")
interBlock

#ggsave(filename = here("Figures","InteractionperBlock.png"), interBlock)

```

