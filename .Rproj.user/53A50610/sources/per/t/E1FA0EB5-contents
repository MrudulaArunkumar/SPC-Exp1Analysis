---
title: "Exp7 Analysis_Overshadowing and contingency awareness"
author: "Mrudula Arunkumar"
date: "`r format(Sys.time(), '%d %B,%Y')`"
output:
  html_document:
    theme: readable
    highlight: breezedark
    toc: yes
    toc_float: yes
    fig_caption: yes
    fig_width: 7
    fig_height: 4
    code_folding: hide
  pdf_document:
    toc: yes
---

**This document contains the result memo of Experiment 7 aimed to explore overshadowing in a contingency learning paradigm. It builds on from the design used in Experiment 5 and 6 that showed success in manipulating saliency and validity.But the interaction was not significant in those experiments, Hence, this experiment works towards that aspect by eliminating the contingency guessing trials in between that resembled the test trials and probably emphasized enough on the nonsalient distractors too. So this experiment has two versions of contingency guessing trials: one that resembles learn trials that are presented in the beginning after the headstart trials in a learn block. Then the other one is similar to the ones in the previous experiment that resemble test trials and appear at the end of the experiment.**

```{r loadlibs, include=FALSE, message=FALSE}

library(tidyverse)
library(plyr)
library(ez)
library(schoRsch)
library(knitr)
library(pander)
library(rmarkdown)
library(reshape2)
library(here) #to avoid setwd &automatically assigns it based on the .here file which is created the first time the file is saved
library(ggpubr)
library(lme4)
library(nlme)
library(lmerTest)
library(car)
library(Rmisc)
#set_here()

Exp7data <- read.csv(here("Data", "Exp7_fulldataset.csv"))
Exp7data$participant <- as.factor(Exp7data$participant)

##removing participants with average performance
`%notin%` <- Negate(`%in%`)

```

Below is the overview of the experiment trials.

```{r image, echo=FALSE, out.width="100%", fig.align = 'center'}
knitr::include_graphics(here("Figures","Trialcount.png"))
```

Here are the sample trial displays

-   Example Learn Trial with G as a salient letter and X as a non salient pair
-   Example test display with salient distractor
-   Example test display with nonsalient distractor
-   The target is an odd/even number appearing at the centre.

```{r trials, echo=FALSE,fig.show="hold", out.width="30%"}
include_graphics(here("Figures","G learn.png"))
include_graphics(here("Figures","G test.png"))
include_graphics(here("Figures","X test trial.png"))
```

# Data preparation and cleaning

-   Removing unnecessary columns generated by psychopy
-   Preparing the RT trial, by eliminating the square brackets and splitting it in cases where two keys were registered.
-   Creating a column for Accuracy and Error Rate
-   adding a Bonus column that computes the points received by each participant
-   Since there were two blocks containing useful RT- one with the CA learn guessing block and other from the remaining experiment block, the RTs that were saved had to be separated and merged together as experiment RTs used for analysis

```{r cleaning, include=FALSE, message=FALSE}
#removing unnecessary columns
Exp7data <- Exp7data %>%
  select(-X,-ConsentKey.keys,-ConsentKey.rt,-Begin.keys,-Begin.rt,-checkresp.corr,-checkresp.keys,-checkresp.rt,-Attention.thisRepN,-Attention.thisTrialN,-Attention.thisN,-Attention.thisIndex,-Attention.ran,-AttnQuestion,-AttnAnswer,-NextStep.keys,-NextStep.rt,-InstRep.ran,-InstRep.thisN,-InstRep.thisTrialN,-InstRep.thisRepN,-InstRep.thisIndex,-PracProceed.keys,-PracProceed.rt,-Prac_loop.thisRepN,-Prac_loop.thisTrialN,-Prac_loop.thisN,-Prac_loop.thisIndex,-Prac_loop.ran,-Exp_proceed.keys,-Exp_proceed.rt,-PracRepeat.ran,-PracRepeat.thisRepN,-PracRepeat.thisN,-PracRepeat.thisIndex,-PracRepeat.thisTrialN,-brkContinue.keys,-PauseResp.keys,-PauseResp.rt,-CALearntrials.thisRepN,-CALearntrials.ran,-CALearntrials.thisTrialN,-CALearntrials.thisIndex, -CA_Proceed.keys,-CA_Proceed.rt,-headstartLearn.thisRepN,-headstartLearn.thisTrialN,-headstartLearn.thisIndex,-headstartLearn.thisN,-headstartLearn.ran,-ExpTrials.ran,-ExpTrials.thisIndex,-CA_trials.thisRepN,-CA_trials.thisN,-CA_trials.thisIndex,-CA_trials.thisTrialN,-CA_trials.ran,-AwareQ_loop.thisRepN,-AwareQ_loop.ran,-AwareQ_loop.thisIndex,-AwareQ_loop.thisTrialN,-todebrief.keys,-Finalend.keys)



#adjusting RT
# here the RTs are stored in two variables as the first block with the Contingency guessing trials like the learn trials were stored in the variable of CAresponse.
Exp7data$mainRT <- Exp7data$TargetResp.rt
Exp7data$Block1RT <- Exp7data$CAResponse.rt

#splitting the RTs from main experimental block
Exp7data <- separate(Exp7data, col = mainRT, into = c("RTm_Trials", "RTm_secondary"), sep = ',')
#sepearte the column as psychopy stores it with square brackets
Exp7data$RTm_Trials <- Exp7data$RTm_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp7data$RTm_Trials)
Exp7data$RTm_Trials <- 1000*(Exp7data$RTm_Trials)

#splitting RTs from the Ca learn block (1st block)
Exp7data <- separate(Exp7data, col = Block1RT, into = c("RTb_Trials", "RTb_secondary"), sep = ',')
Exp7data$RTb_Trials <- Exp7data$RTb_Trials%>%
  str_replace_all("\\[|\\]","")%>%
  as.double(Exp7data$RTb_Trials)

#psychopy saves it as decimal per second
Exp7data$RTb_Trials <- 1000*(Exp7data$RTb_Trials)
#removing RTs from guessing trials 
Exp7data$RTb_Trials <- ifelse(Exp7data$Block == "CG Learn", NA, Exp7data$RTb_Trials)

#creating a dummy variable to pick wherever the RTs are from main block and which are from first block
Exp7data$RTdummy <- ifelse(is.na(Exp7data$TargetResp.rt) == FALSE,1,NA)
Exp7data$RTdummy <- ifelse(is.na(Exp7data$CAResponse.rt)==FALSE,2,Exp7data$RTdummy)

#combining all important RTs 
Exp7data <- Exp7data %>%
  mutate(RT_Trials = ifelse((RTdummy == 1), RTm_Trials,ifelse((RTdummy == 2),RTb_Trials,NA)))

#creating a Bonus column, for prolific

Exp7data <- Exp7data %>%
  mutate(Bonus = ifelse(Target == "?",
                        ifelse((CAResponse.corr == 0&is.na(CAResponse_2.corr))|(CAResponse_2.corr == 0&is.na(CAResponse.corr)),-3,
                               ifelse((CAResponse.corr == 1 &is.na(CAResponse_2.corr))|(CAResponse_2.corr == 1&is.na(CAResponse.corr)),3,NA)),NA))

Exp7data$Bonus <- as.integer(Exp7data$Bonus)

#creating an aggegrate File with bonus
Exp7Bonus <- aggregate(data = Exp7data, Bonus~PROLIFIC_ID, sum)
Exp7Bonus$Perf <- na.omit(Exp7data$Performance)

###creating a separate df with the contingency awareness
Exp7_CA <- Exp7data%>%
 filter(Target == "?" | str_detect(AwareQ, "Press"))

#dropping rows containing NA RTs (for example where there is a break)
Exp7data <- Exp7data%>%drop_na(RT_Trials)

#combining accuracy from first block and main block
Exp7data$mainAcc <- Exp7data$TargetResp.corr
Exp7data$Block1Acc <- Exp7data$CAResponse.corr
Exp7data$BlockAcc <- ifelse(Exp7data$Block == "CG Learn", NA, Exp7data$Block1Acc)

Exp7data$ACCdummy <- ifelse(is.na(Exp7data$TargetResp.corr)==FALSE,1,NA)
Exp7data$ACCdummy <- ifelse(is.na(Exp7data$CAResponse.corr)==FALSE,2,Exp7data$ACCdummy)

Exp7data <- Exp7data %>%
  mutate(ACC_trials = ifelse((ACCdummy == 1),mainAcc,ifelse((ACCdummy == 2),Block1Acc,NA)))

# creating a column for error Rate
Exp7data$ErrorRate <- 1 - Exp7data$ACC_trials


#to check outlier error rate
Exp7ER <- aggregate(data = Exp7data,ErrorRate~participant,mean)
#participant 10 has high error rate


```

## Descriptives

Summary of the overall Reaction Time, accuracy and Error Rate

```{r descriptives, echo=FALSE,results='asis'}
pander(summary(Exp7data$Age), style = 'rmarkdown', caption = "Mean Age")

pander(summary(Exp7data$RT_Trials), style = 'rmarkdown',caption = 'Mean RT')
pander(table(Exp7data$ACC_trials),style = 'rmarkdown',caption = "Accuracy")

pander(round(table(Exp7data$ACC_trials)/nrow(Exp7data)*100, digits = 3), style = 'rmarkdown', caption = "Percentage of errors")
```

Upon implementing the exclusion criteria

-   Outliers (1.5x above third quartile) --rm> used for the analysis
-   Farouts (3x)above third quartile)
-   very Fast RTs, less than 200ms

```{r exclusions, echo=FALSE, results='asis'}
#incorrect trials RT are not used
Exp7data$RT_Trials[Exp7data$ACC_trials==0] <- NA

#removing outlier error rate participant
Exp7data <- Exp7data%>%
  filter(participant != 10)

#creating function to remove the outliers and farouts
computeTukeys <- function(x){
  P25 <- quantile(x$RT_Trials, .25, na.rm = TRUE, type = 6) #type = 6 -> used in SPSS
  P75 <- quantile(x$RT_Trials, .75, na.rm = TRUE, type = 6)
  x$Outlier <- P75 + 1.5*(P75 - P25)
  x$Farouts <- P75 + 3.0*(P75 - P25)
  return(x)
}


#identifying the outliers and farouts at individual level
Exp7data <- ddply(Exp7data, .(participant), computeTukeys)

#creating new column with RT trials after removing outliers/farouts
Exp7data$RT_ifo <- Exp7data$RT_Trials #ifo refers to individual farouts
Exp7data$RT_io <- Exp7data$RT_Trials #io refers to individual outliers

#RTs above outliers and farouts and very fast RTs below 200ms
Exp7data$RT_ifo[Exp7data$RT_ifo > Exp7data$Farouts|Exp7data$RT_ifo < 200] <- NA

Exp7data$RT_io[Exp7data$RT_io > Exp7data$Outlier|Exp7data$RT_io < 200] <- NA

#printing the summary table for RTs columns in rmarkdown style
pander(summary(Exp7data$RT_ifo), style = 'rmarkdown', caption = "Summary of RT after removing Farouts")
pander(summary(Exp7data$RT_io), style = 'rmarkdown', caption = "Summary of RT after removing Outliers")

```

# ANALYSES

## EXPERIMENT DESIGN

```{r flow}
#displaying the pictures of the experiment flow
include_graphics(here("Figures","Experiment flow.png"))
include_graphics(here("Figures", "Experiment design.png"))

```

## 1. Validity Manipulation check - Learn trials

> There is a huge validity effect which is significant with a mean difference of ~50 ms. This significant effect is also present in the Error Rate

This shows that participants successfully picked up the association between the letters and the response keys

```{r valcheck, echo=FALSE,message=FALSE,results='asis'}
##creating an aggregate to check for validity effect
#Exp7learn_agg <- aggregate(data = Exp7data, RT_ifo~participant+Validity,mean)

#only choosing learn block to test for validity effect
Exp7learn_agg_o <- aggregate(data = Exp7data, RT_io~participant+Validity,subset = (Condition == "learn"),mean)
Exp7learn_agg_o_ER <- aggregate(data = Exp7data, ErrorRate~participant+Validity,subset = (Condition == "learn"),mean)

#for farouts
#pander(aggregate(data = Exp7learn_agg, RT_ifo~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, farouts excluded")
#pander((t.test(data = Exp7learn_agg, RT_ifo~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials")



#for outliers exclusion RTs
pander(aggregate(data = Exp7learn_agg_o, RT_io~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, outliers excluded")

# ttest to check whether the difference is significant
pander((t.test(data = Exp7learn_agg_o, RT_io~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials-excluding outliers")


##ER

pander(aggregate(data = Exp7learn_agg_o_ER, ErrorRate~Validity,mean), style = "rmarkdown", caption = "Table containing means of valid and invalid learn trials, ErrorRate")


pander((t.test(data = Exp7learn_agg_o_ER, ErrorRate~Validity,paired = TRUE)), style = 'rmarkdown', caption = "t test showing differences between valid and invalid trials, for ER")


## PLotting the valid and invalid RTs
valmain <- ggplot(Exp7learn_agg_o, aes(x=Validity, y=RT_io))+
    geom_line(aes(group = 1, color = "deepskyblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Validity, color = "deepskyblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(550,650))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean of valid and invalid trials")+theme(text = element_text(size = 20))
valmain

# Plotting the valid and invalid ERs
valmainER <- ggplot(Exp7learn_agg_o_ER, aes(x=Validity, y=ErrorRate))+
    geom_line(aes(group = 1, color = "deepskyblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Validity, color = "deepskyblue4"),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(0,0.20))+
  scale_color_manual(values = c("deepskyblue4"))+
  theme_classic()+ylab("Error Rate")+ggtitle("Mean of valid and invalid trials, ER")+theme(text = element_text(size = 20))
valmainER

#ggsave(filename = here("Figures","Validity_main.png"),valmain)
#ggsave(filename = here("Figures","Validity_main_ER.png"),valmainER)
```

## 2. Saliency Manipulation Check

This analysis checks whether the saliency manipulation worked by comparing the RT between trials where the number appeared in salient letter's position vs non salient letter's position.

> There is a significant difference between trials where the target appeared at the salient letter position vs non salient letter's position ($p = 0.01*$)

```{r salcheck, echo=FALSE, message=FALSE,results='asis'}
# Exp7SalCheck <- aggregate(data = Exp7data, RT_ifo~participant+Saliency, subset = (Block == "SalMC"), mean)
##only selecting the trials from the saliency manipulation check, Sal MC, block
Exp7SalCheck_o <- aggregate(data = Exp7data, RT_io~participant+Saliency, subset = (Block == "SalMC"), mean)

# 
# pander(t.test(RT_ifo~Saliency, data = Exp7SalCheck,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation")

pander(t.test(RT_io~Saliency, data = Exp7SalCheck_o,paired=TRUE),style = "rmarkdown", caption = "t test result for saliency manipulation, outliers excluded")

salmain <- ggplot(Exp7SalCheck_o, aes(x=Saliency, y=RT_io,color = Saliency))+
    geom_line(aes(group = 1),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+
  geom_point(aes(group = Saliency, shape = Saliency),size = 1,stat = "summary", fun = "mean",show.legend = FALSE)+coord_cartesian(ylim = c(600,700))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Mean of trial with target behind salient vs non salient distractor")+theme(text = element_text(size = 20))
salmain
#ggsave(filename = here("Figures","Saliency_main.png"),salmain)
```

## 3. Interaction of Validity x Saliency in test trials

This analysis is the main one concerning overshadowing.

1.  Farouts: Not analyzed further as outliers prove to be a better exclusion criteria

```{r interactionfo, eval=FALSE, warning=FALSE, message=FALSE}

## aggregating the data for farouts and for outliers

Exp7agg_fo <- aggregate(data = Exp7data, RT_ifo~participant+Validity+Saliency, subset = (Condition == "test"), mean)





anova_VS_fo <- ezANOVA(data = Exp7agg_fo,
                       dv = RT_ifo,
                       wid = participant,
                       within = .(Validity, Saliency),type = 3,
                       detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VS_fo, style = "rmarkdown", caption = "ANOVA for test trials with Validity and Saliency as factors",split.table = Inf, missing = NA)

# aov_VS_fo <- aov(RT_ifo~(Validity*Saliency)+Error(participant/(Validity*Saliency)), data = Exp7agg_fo)
# summary(aov_VS_fo)

ezPlot(data = Exp7agg_fo,
        dv = RT_ifo,
        wid = participant,
        within = .(Validity, Saliency),
       split = Validity, x = Saliency, do_bars = FALSE)+theme_classic()+
  ggtitle("Interaction effect between saliency and validity for test trials")



#stdInteraction_fo <- ggplot(Exp7agg_fo, aes(x=Saliency, y=RT_ifo,color = Validity))+
#    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
#    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+ylim(500,600)+
#  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
#  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")

#ggsave(filename = here("Figures","interaction_fo.png"),stdInteraction_fo)

mean_valEffect_fo <- ezStats(data = Exp7agg_fo,
        dv = RT_ifo,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)

pander(mean_valEffect_fo, style = "rmarkdown", title = "Validity effect(invalid-valid) for salient and non salient letters in test trials(farouts)")


pander(t.test(data = Exp7agg_fo, RT_ifo~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, farouts")
```

2.  Outliers:

The validity effect is not significant, $F = 2.07, p = 0.15$, however the main effect of saliency and the interaction between validity and saliency are significant in the right direction.

```{r interactiono, warning=FALSE, message=FALSE, results='asis'}
##for outliers
  #aggregating data within participant for ANOVA analysis. Only test trials are used.
Exp7agg_o <- aggregate(data = Exp7data, RT_io~participant+Validity+Saliency, subset = (Condition == "test"), mean)

#ANOVA
anova_VS_o <- ezANOVA(data = Exp7agg_o,
                       dv = RT_io,
                       wid = participant,
                       within = .(Validity, Saliency),
                       detailed = TRUE)
#displaying the aova result output for rmarkdown
panderOptions('table.split.table',300)
pander(anova_VS_o, style = "rmarkdown", caption = "ANOVA for test trials(w/o outliers) with Validity and Saliency as factors",split.table = Inf, missing = NA)


#plotting the graph showing the interaction
stdInteraction_o <- ggplot(Exp7agg_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(550,600))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency")+theme(text = element_text(size = 20))
stdInteraction_o
#ggsave(filename = here("Figures","interaction_o.png"),stdInteraction_o,width = 6,height = 4)

```

Here is a closer look at the effects, showing the mean difference between valid and invalid in each condition. T tests show that the difference is significant for salient trials and not significant for nonsalient trials

```{r meandiff, echo = FALSE, warning=FALSE, results='asis'}
## performing a t test within each saliency condition to test how significant the difference in validity is. 
 pander(t.test(data = Exp7agg_o, RT_io~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for nonsalient trials, outliers")

pander(t.test(data = Exp7agg_o, RT_io~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials, outliers")

#creating a mean df across all participants per condition with ci to compute paired differences to be used for the error bars in the graphs
meanSalVal <- summarySEwithin(Exp7agg_o, measurevar = "RT_io", withinvars = c("Saliency","Validity"), idvar = "participant", na.rm = FALSE, conf.interval = .95)

#the bargraph with mean difference
salvalmean <- ggplot(meanSalVal, aes(x=Saliency, y=RT_io,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = RT_io - ci, ymax =RT_io + ci),width = .2, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(500,600))+
  theme_minimal()+ylab("ReactionTime (in ms)")+theme(text = element_text(size = 20)) 
salvalmean
#ggsave(filename = here("Figures","Barplot_SalxVal_RT.png"),salvalmean)

#Mean difference computed to plot the validity effect as y axis
mean_valEffect_o <- ezStats(data = Exp7agg_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        reverse_diff = TRUE)


pander(mean_valEffect_o, style = "rmarkdown", caption =  "Validity effect(invalid-valid) for salient and non salient test trials(outliers)")





##for outliers

Valeffectplot <- ggplot(mean_valEffect_o, aes(x=Saliency, y=Mean,fill = Saliency))+
    geom_bar(stat = "identity")+
  scale_fill_manual(values = c("cadetblue3","dodgerblue4"))+
  theme_classic()+ylab("Validity effect (invalid - valid trials) in ms")+ggtitle("Difference between invalid and valid trials")+theme(text = element_text(size = 20))
Valeffectplot

#ggsave(filename = here("Figures","Valeffectplot_o.png"),Valeffectplot,width = 6, height = 4)

```

## 4. Error Rate

> Error Rate data show a significant main effect of validity and a significant interaction of validity and Saliency

```{r Errorate, message=FALSE, warning=FALSE,results='asis'}

##aggregate file for Error Rate with Validity and Saliency
Exp7agg_ER <- aggregate(data = Exp7data,ErrorRate~participant+Validity+Saliency,subset = (Condition == "test"),mean)



anova_t_ER <- ezANOVA(data = Exp7agg_ER,
        dv = ErrorRate,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_ER, style = 'rmarkdown', caption = "ANOVA results: ErrorRates in test trials", split.table = "Inf", missing = NA)

anova_out(anova_t_ER)

#interaction plot
errorrateplot <-  ggplot(Exp7agg_ER, aes(x=Saliency, y=ErrorRate,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(0,0.15))+
  theme_classic()+ylab("Error Rate")+ggtitle("Interaction of Validity and Saliency with ErrorRate as DV")
errorrateplot
#ggsave(filename = here("Figures","ErrorRate.png"),errorrateplot,width=6,height = 4)

#computing means per condition across all participants with paired differences CI for error bar in the graph
meanSalValER <- summarySEwithin(Exp7agg_ER, measurevar = "ErrorRate", withinvars = c("Saliency","Validity"), idvar = "participant", na.rm = FALSE, conf.interval = .95)

salvalmeanER <- ggplot(meanSalValER, aes(x=Saliency, y=ErrorRate,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = ErrorRate - ci, ymax = ErrorRate + ci),width = .2, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(0,0.15))+
  theme_minimal()+ylab("Error Rate")+theme(text = element_text(size = 20)) 
salvalmeanER

#ggsave(filename = here("Figures","Barplot_SalxVal_ER.png"),salvalmeanER,width=6,height = 4)
```

## 5. Inverse Efficiency scores and Balance Integration Score

1.  The Inverse Efficiency score ([Bruyer, R & Brysbaert, M., 2011](https://www.psychologicabelgica.com/articles/abstract/10.5334/pb-51-1-5/)) simply combines the RT and Error Rate into a single variable, $IES = RT/(1-ErrorRate)$

2.  The Balance Integration Score (Liesefeld & Jancyzk, 2019) is another form of combining RT and Error Rate but in contrast to the IES, the BIS standardizes the two variables and computes a single variable using this formula, $BIS = z(1-ErrorRate) - z(RT)$

This [research article](https://link.springer.com/article/10.3758/s13428-018-1076-x#Bib1) talks about these methods in depth

```{r faroutsies, include=FALSE}
## create a df that contains both Errorrate and RT

Exp7test <- Exp7data %>%
  subset(Condition == "test")
```

Outliers

1.  **with IES as Dependant variable**

> There is a significant valdity effect and an interaction with validity and saliency

The ANOVA results along with the interaction plot are shown below. The mean difference graph is also presented to have a different visualization of the effects.

```{r outliersiesbis, warning=FALSE, message=FALSE,results='asis'}

###FOR outlier excluded RTs, creating an aggregated df with both RTs and Errorrate, so that IES can be computed

Exp7agg_IES_o <- aggregate(Exp7test[,c("RT_io","ErrorRate","ACC_trials")], by = list(participant = Exp7test$participant,
                                                                       Validity = Exp7test$Validity,
                                                                       Saliency = Exp7test$Saliency), mean,na.rm = TRUE)

#creating column IES that ocmputes the value based on RT and ER
Exp7agg_IES_o$IES <- Exp7agg_IES_o$RT_io/(1-Exp7agg_IES_o$ErrorRate)

#crreating a standardized RT score
Exp7agg_IES_o$ZRT <- scale(Exp7agg_IES_o$RT_io)
#creating a standardized score for the Accuracy
Exp7agg_IES_o$ZPC <- scale(Exp7agg_IES_o$ACC_trials)
#these standardised scores are then used to compute the balanced integration score in the same df
Exp7agg_IES_o$BIS <- Exp7agg_IES_o$ZPC - Exp7agg_IES_o$ZRT

##with IES
anova_t_IES_o <- ezANOVA(data = Exp7agg_IES_o,
        dv = IES,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_IES_o, style = 'rmarkdown', caption = "ANOVA results: using IES(outliers)", split.table = "Inf", missing = NA)

IESinterplot_o <- ggplot(Exp7agg_IES_o, aes(x=Saliency, y=IES,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(600,700))+
  theme_classic()+ylab("IES (in ms)")+ggtitle("Interaction of Validity and Saliency")
IESinterplot_o
#ggsave(filename = here("Figures","IESinterplot_o.png"),IESinterplot_o)

### Validity effect plot preparation ####
meanIES_o <- ezStats(data = Exp7agg_IES_o,
        dv = IES,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff = .(Validity),
        reverse_diff = TRUE)

pander(meanIES_o, style = "rmarkdown", caption = "Mean IES score validity effect")

valeffectIES_o <- ggplot(data = meanIES_o, aes(x = Saliency, y = Mean, fill = Saliency))+scale_fill_manual(values = c("cadetblue3","deepskyblue4"))+
  geom_bar(stat = "identity")+
  theme_classic()+
  ylab("Validity Effect(invalid-valid trials) in ms")+theme(legend.title = element_blank())+
  ggtitle("Validity Effect (invalid - valid) across test trials (IES) averaged across participant")
valeffectIES_o
#ggsave(filename = here("Figures","valEffectwithIES_o.png"),valeffectIES_o)


### Bar plot preparation ###

meanSalValIES <- summarySEwithin(Exp7agg_IES_o, measurevar = "IES", withinvars = c("Saliency","Validity"), idvar = "participant", na.rm = FALSE, conf.interval = .95)


salvalmeanIES <- ggplot(meanSalValIES, aes(x=Saliency, y=IES,fill = Validity))+
  geom_bar(stat = "identity",position = position_dodge())+
  geom_errorbar(aes(ymin = IES - ci, ymax = IES + ci),width = .2, size = 1,position = position_dodge(.9))+
    # geom_line(aes(group = Saliency, linetype = Saliency),size = 1,stat = "summary", fun = "mean",)+
    # geom_point(stat = "summary", fun = "mean", aes(shape = Saliency))+
  scale_fill_manual(values = c("dodgerblue4","cadetblue3"))+coord_cartesian(ylim = c(550,700))+
  theme_minimal()+ylab("IES (in ms)")+theme(text = element_text(size = 20))  
salvalmeanIES

#ggsave(filename = here("Figures","Barplot_salxval_IES.png"),salvalmeanIES)

```

2.  **with BIS as dependent variable**

> There is a significant validity effect and a significant interaction between validity and saliency

The ANOVA and the interaction plot are shown below. *To be noted in the plot: The y axis is represented as a z score*

```{r BIS, warning=FALSE, message=FALSE, results='asis'}
##with BIS
anova_t_BIS_o <- ezANOVA(data = Exp7agg_IES_o,
        dv = BIS,
        wid = participant,
        within = .(Saliency,Validity),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_BIS_o, style = 'rmarkdown', caption = "ANOVA results: using BIS(outliers)", split.table = "Inf", missing = NA)

# interaction plot with BIS as dv
BISinterplot_o <- ggplot(Exp7agg_IES_o, aes(x=Saliency, y=BIS,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+
  theme_classic()+ylab("BIS (z score difference)")+ggtitle("Interaction of Validity and Saliency")
BISinterplot_o
#ggsave(filename = here("Figures","BISinterplot_o.png"),BISinterplot_o)

## remaining plots were not used as only IES was reported in the manuscript
```

The mean difference is also significant for both types of scores in the salient condition and not in the nonsalient condition

1.  **IES**

```{r iesmean, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}

##outliers
pander(t.test(data = Exp7agg_IES_o, IES~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp7agg_IES_o, IES~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

2.  **BIS**

```{r meanBIS, echo=FALSE, message=FALSE, warning=FALSE,results='asis'}
##outliers
pander(t.test(data = Exp7agg_IES_o, BIS~Validity, subset = (Saliency == "Salient"), paired = TRUE), style = "rmarkdown", caption = "Outlier:t. test result of validity effect for salient trials")

pander(t.test(data = Exp7agg_IES_o, BIS~Validity, subset = (Saliency == "NonSalient"), paired = TRUE), style = "rmarkdown", caption = "OUtlier:t. test result of validity effect for nonsalient trials")
```

## 6. Previous Occurence Analysis (Distance & Response Type)

Computing a new column that contains the last time/number of trials ago the previous occurrence occurred.

Eg., Distance = 1 means that the last time the distractor appeared was one trial ago, Distance = 5 means the last time the Distractor appeared was 5 trials ago.

The conditions used to satisfy this last occurrence are:

-   Whether last trial was test/learn (*Since the trials are intermixed*)
-   Whether the Salient **OR** Non salient Distractor appeared.
-   The last occurrence was a trial that was answered correctly

```{r prevocc, message=FALSE, warning=FALSE}
#moving all the necessary columns to the front for easy reference
Exp7data <- Exp7data%>%select(Condition, SalD,NSalD,Saliency,Validity, everything())

###first is to find out the trials where the previous occurence was the immediate previous one

#creating new column which is the distance
Exp7data$Distance <- NA
Exp7data <- Exp7data%>%select(Distance,ACC_trials,everything())
# filling up the distance column by checking whether - immediately previous trial (n-1) was a test or learn trials, whetehr it had the same distractor as n, within the same participant and if it is an accurate trial
Exp7data <- Exp7data%>%
  mutate(Distance = ifelse((lag(Condition,1)=="test" | lag(Condition,1) == "learn")& 
              (lag(SalD,1)== SalD|lag(NSalD,1)==NSalD) &
                            lag(participant,1)==participant &
                            lag(ACC_trials,1)== 1, 1, Distance))

#The number of immediate previous occurences
pander(table(Exp7data$Distance), style = 'rmarkdown', caption = "Table showing the number of immediate previous occurence")

## Now to look at other distances of the last occurrence beyond the immediately preceding one
lagvalue <- 2:20

#same as above but here j will refere to the n - jth trial where the last occurence occurred.
for(j in lagvalue){
  Exp7data <- Exp7data %>% 
    mutate(Distance = ifelse((lag(Condition,j)=="learn"|lag(Condition,j)=="test") &                     (lag(SalD,j)==SalD|lag(NSalD,j)==NSalD) & lag(participant,j)==participant & lag(ACC_trials,j)== 1 & is.na(Distance)==TRUE, j, Distance))
}

pander(table(Exp7data$Distance), style = 'rmarkdown', caption = "Table showing the number of total previous occurences and how far each of them are")

```

### Previous Response

Coding what the previous Response was, whether it was the same or different. This variable is defined as Response Relation, which has two factors: Response Change(RC) and Response Repetition (RR)

*To be noted: This does not equate to validity* because the SRB trials can have the combination of invalid prime and invalid probe --> Response Repetition which is confounded by Validity. So every valid probe can have both the Response Type factors based on whether the prime is valid or invalid

```{r disttype, message=FALSE, warning=FALSE}

Exp7data$ResponseRel <- NA


Exp7data <- Exp7data %>% 
  mutate(ResponseRel = ifelse((lag(Condition,1)=="learn" | lag(Condition,1)=="test") & lag(participant,1)==participant & lag(CorrectAnswer,1)== CorrectAnswer & is.na(ResponseRel)==TRUE, "RR", ifelse((lag(Condition,1)=="learn"|lag(Condition,1)=="test") & lag(participant,1)==participant & lag(CorrectAnswer,1)!= CorrectAnswer & is.na(ResponseRel)==TRUE, "RC", ResponseRel)))


pander(table(Exp7data$ResponseRel),style = 'rmarkdown', caption = "Total number of RRs and RCs")

Exp7data <- Exp7data%>%select(ResponseRel, everything())

```



### Overshadowing within SRB

**For more detailed analysis, check Exp7-BindingEffects analyses.html**

Another variable(Overshadow SRB) can also be computed that checks for overshadowing effects within a SRB Trial. So in this case, naturally only the trials with last occurence Distance = 1 will be considered.

The conditions used to determine this variable are:

-   Trial $n$ is a test trial and trial $n-1$ is a learn trial and prime trial is accurate.
-   Test Trial's distractor saliency = Salient and also same as the distractors presented in the prime learn trial, then the OvershadowSRB = 1
-   Test Trial's distractor saliency = Nonsalient and also same as the distractors presented in the prime learn trial, then the OvershadowSRB = 2

So essentially, OvershadowSRB tells about the saliency of the test trial (replacing the Saliency factor in the main data)

```{r overSRB, message=FALSE, warning=FALSE}
#creating a new variable that basically equates to saliency of trial n
Exp7data$ProbeSaliency <- NA

Exp7data <- Exp7data%>%select(ProbeSaliency, everything())

#Salient is referred to as 1
Exp7data <- Exp7data %>%
  mutate(ProbeSaliency = ifelse((Condition == "test" & lag(Condition,1) == "learn") &
           lag(SalD,1) == SalD & lag(participant,1)==participant & lag(ACC_trials,1)==1, 1,ProbeSaliency))

#nonsalient is referrred to as 2
Exp7data <- Exp7data %>%
  mutate(ProbeSaliency = ifelse((Condition == "test" & lag(Condition,1) == "learn") &
           lag(NSalD,1)==NSalD & lag(participant,1)==participant & lag(ACC_trials,1)==1 & is.na(ProbeSaliency) == TRUE,2,ProbeSaliency))


table(Exp7data$ProbeSaliency)
Exp7data<- Exp7data%>%select(CorrectAnswer, everything())
##creating a dataframe that has only Binding trials preceding with learn 
Exp7_OverSRB <- Exp7data %>%
  subset(ProbeSaliency %in% c('1','2'))

Exp7_OverSRB<- Exp7_OverSRB%>%select(CorrectAnswer, everything())
#table(Exp7_OverSRB$ProbeSaliency,Exp7_OverSRB$ResponseRel)
```

#### ANOVA: interaction between Response Type and Saliency for binding trials

Exploratory ANOVA to check how overshadowing looks at a Binding level, using Retrieval effect (ResponseRel) as the variable to check how Saliency affects retrieval.

Aggregate file is created only using the factors of ProbeSaliency and ResponseRel, without Validity because when Validity is included it leads to more missing values and imbalanced data.

> The results show a significant interaction between probe saliency and ResponseRel(repeats/changes) and a main effect of probe saliency (overshadow SRB)

```{r anovaSRB, warning=FALSE, message=FALSE,results='asis'}

Exp7overSRB_Agg <- aggregate(Exp7_OverSRB[,c("RT_io","ErrorRate")], by = list(participant=Exp7_OverSRB$participant,ProbeSaliency = Exp7_OverSRB$ProbeSaliency,ResponseRel = Exp7_OverSRB$ResponseRel,Validity=Exp7_OverSRB$Validity), mean, na.rm = TRUE)

Exp7overSRB_Agg <- Exp7overSRB_Agg %>%
   mutate(ProbeSaliency = ifelse(ProbeSaliency == 1, "Salient","NonSalient"))
Exp7overSRB_Agg$ProbeSaliency <- as.factor(Exp7overSRB_Agg$ProbeSaliency)

#ANOVA
#ezANOVA does not work due to imbalanced design so aov function is used.
anovaSRB <- aov(RT_io~(Validity*ProbeSaliency*ResponseRel)+Error(participant/(Validity*ProbeSaliency*ResponseRel)), data = Exp7overSRB_Agg)
pander(anovaSRB, style = 'rmarkdown', caption = "ANOVA results for binding trials with Response Type and Probe Saliency")


srbInteraction_o <- ggplot(Exp7overSRB_Agg, aes(x=ProbeSaliency, y=RT_io,color = ResponseRel))+
    geom_line(aes(group = ResponseRel, linetype = ResponseRel),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = ResponseRel))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+xlab("Probe Saliency")+theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of ResponseRelation and Saliency for Probe Trials")+facet_grid(.~Validity)+theme(text = element_text(size = 20))
srbInteraction_o
ggsave(filename = here("Figures","SRB3factors.png"),srbInteraction_o)

#testing the strength of the retrieval effects for salient and nonsalient distractor
pander(t.test(data =Exp7overSRB_Agg, RT_io~ResponseRel, subset = (ProbeSaliency == "Salient"),paired = TRUE), style = "rmarkdown", caption = "T test result for Retrieval effect for Salient probes")
# 
pander(t.test(data =Exp7overSRB_Agg, RT_io~ResponseRel, subset = (ProbeSaliency == "NonSalient"),paired = TRUE),style = "rmarkdown", caption = "T test result for Retrieval effect for NonSalient probes")


```

#### ANOVA: Interaction between validity and Saliency *without* Binding trials

This analysis looks at the interaction of validity and saliency after the Stimulus repetition trials are removed.

> The interaction and the main effects are not significant anymore.

```{r anovawoSRB,message=FALSE,warning=FALSE}

Exp7woSRB <- Exp7data %>%
  filter(Distance != 1)

Exp7woSRB_Agg <- aggregate(Exp7woSRB[,c("RT_io","ErrorRate")], by = list(participant=Exp7woSRB$participant,
                                                                        Saliency = Exp7woSRB$Saliency, Validity = Exp7woSRB$Validity), mean, na.rm = TRUE)

Exp7woSRB_Agg <- Exp7woSRB_Agg %>%
  filter(Saliency%in%c("Salient","NonSalient"))

anovaWoSRB <- ezANOVA(data = Exp7woSRB_Agg,
                      dv = RT_io,
                      wid = participant,
                      within = .(Saliency,Validity),
                      detailed = TRUE)
panderOptions('table.split.table',300)
pander(anovaWoSRB, style = "rmarkdown", caption = "ANOVA after removing stimulus repetition trials", split.table = "Inf", missing=NA)


woSRBinter <- ggplot(Exp7woSRB_Agg, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+coord_cartesian(ylim = c(550,650))+
  theme_classic()+ylab("ReactionTime (in ms)")+ggtitle("Interaction of Validity and Saliency after removing the binding trials")
woSRBinter
#ggsave(filename = here("Figures","woSRBinteraction.png"),woSRBinter)
```

### Multi level model

Check other memo titled "Exp7-mlm.html"

# Exploratory Analyses

This exploratory analysis involves the factors of contingency awareness from the guessing trials and the awareness questionnaire responses

## 1. Block Analysis

> There is a significant main effect of Block and the interaction between saliency and validity remains significant.

The plot shows that the second block especially shows the trend as expected. But this is not significant on its own (i.e., only when second block is analyzed).

```{r block, warning=FALSE, message=FALSE}

Exp7data <- Exp7data %>%
  mutate(BlockCount = ifelse(ExpTrials.thisN <= 145, 1, ifelse(ExpTrials.thisN > 145 & ExpTrials.thisN <= 295,2,NA)))

Exp7agg_B_o <- aggregate(data = Exp7data, RT_io~participant+Validity+Saliency+BlockCount, subset = (Condition == "test"), mean)


##Anova with Blocks
anova_t_block <- ezANOVA(data = Exp7agg_B_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity,BlockCount),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_t_block, style = 'rmarkdown', caption = "ANOVA results: with BlockCount", split.table = "Inf", missing = NA)


interBlock <- ggplot(Exp7agg_B_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~BlockCount)+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency per Block")
interBlock

#ggsave(filename = here("Figures","InteractionperBlock.png"), interBlock)

```

## 2. Contingency Awareness guessing trials

These are the trials that were presented in between the experiment. First in the beginning among the learn trials and then at the end. There are a total of 20 Guessing trials: - 16 in the beginning that resembled the learn trials where 8 of them had the salient letter alone among other irrelevant blue letters and 8 had the nonsalient letter presented among the blue distractors with a randomly assigned red letter - 4 at the end that resembled the test display - One presentation each of the distractors (2 salient and 2 non salient)

```{r prepCA, include=FALSE}

Exp7_CA <- Exp7_CA %>%
  select(-TargetResp_p.corr,-TargetResp_p.keys,-TargetResp_p.rt,-TargetResp.corr,-TargetResp.keys,-todebrief.rt,-Finalend.rt)

Exp7_CA <- Exp7_CA %>%
  dplyr::rename(CGLearntrial = CALearntrials.thisN)
Exp7_CA$AwareResp.corr <- as.factor(Exp7_CA$AwareResp.corr)
Exp7_CA$AwareResp.keys <- as.character(Exp7_CA$AwareResp.keys)
Exp7_CA$Solution <- as.character(Exp7_CA$Solution)


Exp7_CA$SalTotalAcc <- NA
Exp7_CA$NonSalTotalAcc <- NA

Exp7_CA <- Exp7_CA %>%
  mutate(Test_SalTotalAcc = ifelse(Saliency == "Salient" & CAResponse_2.corr == 1, 1, 0))


Exp7_CA <- Exp7_CA %>%
  mutate(Learn_SalTotalAcc = ifelse(Saliency == "Salient" & CAResponse.corr == 1, 1, 0))

Exp7_CA <- Exp7_CA %>%
  mutate(Test_NonSalTotalAcc = ifelse(Saliency == "NonSalient" & CAResponse_2.corr == 1, 1, 0))
Exp7_CA <- Exp7_CA %>%
  mutate(Learn_NonSalTotalAcc = ifelse(Saliency == "NonSalient" & CAResponse.corr == 1, 1, 0))

Exp7_CA <- Exp7_CA %>%
  mutate(LearnGuessOrder = ifelse(CGLearntrial <= 19,1,
                            ifelse(CGLearntrial > 19 & CGLearntrial <=38,2,
                             ifelse(CGLearntrial > 38 & CGLearntrial <=57,3,
                              ifelse(CGLearntrial > 57 & CGLearntrial <=76,4,
                               ifelse(CGLearntrial > 76 & CGLearntrial <=95,5,NA))))))
table(Exp7_CA$LearnGuessOrder)
cor.test(Exp7_CA$CAResponse.corr, Exp7_CA$LearnGuessOrder, method = "pearson")

correlQnoAcc <- ggplot(Exp7_CA, aes(x = CAResponse.corr, y = LearnGuessOrder))+
  geom_jitter(aes(x = CAResponse.corr, y = LearnGuessOrder), color = "seagreen")+
  stat_smooth(method = "lm", color = "seagreen")+theme_classic()+xlab("Accuracy in learn guessing trials")+ylab("Occurence order of the Learn guessing trials")+ggtitle("Correlation between accuracy and the occurence of the learn trials")
correlQnoAcc

CA_Summary <- Exp7_CA %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(LearnCA_Acc = (sum(CAResponse.corr, na.rm=TRUE)),
                   MeanLearnAcc = mean(CAResponse.corr, na.rm=TRUE)*100,
                   TestCA_Acc = (sum(CAResponse_2.corr, na.rm = TRUE)),
                   MeantestAcc = mean(CAResponse_2.corr, na.rm = TRUE)*100,
                   LearnSalAcc = (sum(Learn_SalTotalAcc, na.rm = TRUE)),
                   LearnNonSalAcc = sum(Learn_NonSalTotalAcc, na.rm = TRUE),
                   TestSalAcc = sum(Test_SalTotalAcc, na.rm = TRUE),
                   TestNonSalAcc = sum(Test_NonSalTotalAcc, na.rm = TRUE)) 
CA_Summary <- CA_Summary %>%
  group_by(participant)%>%
  mutate(TotalGuessingAcc = LearnCA_Acc + TestCA_Acc) %>%
  ungroup()


CA_Summary$participant <- as.factor(CA_Summary$participant)

Exp7Aware <- merge(Exp7agg_o,CA_Summary, by = c("participant"))
```

These plots show the overall accuracy of the participants in the guessing trials that were spread across the experiment.

The plot shows that in the Guess trials resembling Learn trials- most participants seemed to be scoring better for the Salient trials compared to the non salient. Similarly in the test trial condition, salient trials seemed to have larger proportion of participants answering accurately than non salient.

```{r CA plot, echo=FALSE, message=FALSE, warning=FALSE}




testsal <- ggplot(CA_Summary, aes(x = TestSalAcc, fill = "dodgerblue4"))+
  geom_bar(aes(x= TestSalAcc), show.legend = FALSE)+scale_fill_manual(values = c("dodgerblue4"))+
  theme(legend.title = element_blank())+ggtitle("Participants performance in Test Salient trials")+theme_classic()
testsal

testnonsal <- ggplot(CA_Summary, aes(x = TestNonSalAcc, fill = "cadetblue3"))+
  geom_bar(aes(x= TestSalAcc))+scale_fill_manual(values = c("cadetblue3"))+
  theme(legend.position = "none")+ggtitle("Participants performance in Test NonSalient trials")+theme_classic()
testnonsal


learnsal <- ggplot(CA_Summary, aes(x = LearnSalAcc, fill = "darkred"))+
  geom_bar(aes(x= TestSalAcc))+scale_fill_manual(values = c("darkred"))+
  theme(legend.title = element_blank())+ggtitle("Participants performance in Learn Salient trials")+theme_classic()
learnsal

learnnonsal <- ggplot(CA_Summary, aes(x = LearnNonSalAcc, fill = "salmon"))+
  geom_bar(aes(x= TestSalAcc))+scale_fill_manual(values = c("salmon"))+
  theme(legend.position = "none")+ggtitle("Participants performance in Learn NonSalient trials")+theme_classic()
learnnonsal

grid.arrange(testsal,testnonsal,learnsal,learnnonsal, nrow =2)

```




The difference between Accuracy of Guessing trials in the learn trials are as follows:

1.  For the Guessing trials in the learn block, the accuracy significantly differs between saliency
2.  For the Guessing trials at the end of the experiment resembling test trials, they do not differ significantly but almost $p = 0.07$ *two-sided*.

```{r}
pander(t.test(data = CA_Summary, LearnSalAcc~LearnNonSalAcc,paired = TRUE), style = "rmarkdown", caption = "t.test comparing scores between salient and nonsalient guessing learn trials")

pander(t.test(data = CA_Summary, TotalAcc~Saliency,subset = (Condition == "test"),paired = TRUE), style = "rmarkdown", caption = "t.test comparing scores between salient and nonsalient guessing learn trials")
```


## 3. Awareness Questionnaire

The accuracy for the questions related to the salient letter are aggregated and given an overall score of 1 if they answered both the questions right and 0 if one or both are wrong.

For each trial however if they answered correctly, accuracy is marked as 2 and 1 indicates that either they responded incorrectly or do not know.

> 53 people have awareness of contingency for both the salient letters

```{r awareprep, include=FALSE}
Exp7_CA$AwareResp.corr <- as.numeric(Exp7_CA$AwareResp.corr)
AWarepp <- aggregate(data = Exp7_CA, AwareResp.corr~participant+AwareQ_loop.thisN+AwareQ,mean)
AWarepp$AccDicho <- ifelse(AWarepp$AwareResp.corr == 2,1,0)
AWarepp$SalDicho <- ifelse(AWarepp$AwareQ_loop.thisN == "2" & AWarepp$AwareResp.corr == 2 | AWarepp$AwareQ_loop.thisN == "3" & AWarepp$AwareResp.corr== 2,1,0)

pander(table(AWarepp$AwareQ,AWarepp$AwareResp.corr), style = "rmarkdown", title = "Question number and the number of participants answering accurately (1) or not (0)")
# table(AWarepp$Dicho)

A_Summary <- AWarepp %>%
  dplyr::group_by(participant) %>%
  dplyr::summarise(TotalQAcc = sum(AccDicho, na.rm = TRUE),
                   MeanQAcc = mean(AccDicho, na.rm = TRUE),
                   SaliencyAware = sum(SalDicho, na.rm=TRUE))%>%
  filter(participant != 10)

A_Summary$AwareQSal <- ifelse(A_Summary$SaliencyAware == "2" ,1,0)
pander(table(A_Summary$AwareQSal), style = "rmarkdown", caption = "Number of participants with awareness(1)")

Exp7Aware <- merge(Exp7Aware,A_Summary, by = "participant")
```
## using Learn Sal Score as ANCOVA

```{r}
anovaG_VS <- aov(data = Exp7Aware, RT_io~Validity*Saliency*LearnSalAcc)

pander(Anova(anovaG_VS, type = "III"), style = "rmarkdown", caption = "ANCOVA results with guessing accuracy (type 3 SS)")
summary(anovaG_VS)


##For ErrorRate
Exp7agg_Aware_ER <- merge(Exp7agg_ER, CA_Summary,by=c("participant","Saliency"))
Exp7agg_Aware_ER <- merge(Exp7agg_Aware_ER,A_Summary, by = "participant")
anovaG_VSer <- aov(data = Exp7agg_Aware_ER, ErrorRate~Validity*Saliency*LearnSalAcc)


pander(Anova(anovaG_VSer, type = "III"), style = "rmarkdown", caption = "ANCOVA results with guessing accuracy (type 3 SS)")
summary(anovaG_VS)

AcccovarER <- ggplot(Exp7agg_Aware_ER, aes(x = LearnCA_Acc, y = ErrorRate,group = Validity))+
  geom_jitter(aes(x = LearnSalAcc, y = ErrorRate, color = Validity))+stat_smooth(aes(x=LearnSalAcc, y = ErrorRate, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarER

AcccovarRT <- ggplot(Exp7guess, aes(x = LearnSalAcc, y = RT_io,group = Validity))+
  geom_jitter(aes(x = LearnSalAcc, y = RT_io, color = Validity))+stat_smooth(aes(x=LearnSalAcc, y = RT_io, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarRT
```

## using TestSalAcc

```{r}
anovaG_VS_test <- aov(data = Exp7Aware, RT_io~Validity*Saliency*TestSalAcc)

pander(Anova(anovaG_VS_test, type = "III"), style = "rmarkdown", caption = "ANCOVA results with guessing accuracy (type 3 SS)")
summary(anovaG_VS)


##For ErrorRate
anovaG_VSer_test <- aov(data = Exp7agg_GuessAware_ER, ErrorRate~Validity*Saliency*TestSalAcc)

pander(Anova(anovaG_VSer_test, type = "III"), style = "rmarkdown", caption = "ANCOVA results: ER with guessing accuracy (type 3 SS)")
summary(anovaG_VS)



AcccovarERtest <- ggplot(Exp7agg_GuessAware_ER, aes(x = TestSalAcc, y = ErrorRate,group = Validity))+
  geom_jitter(aes(x = TestSalAcc, y = ErrorRate, color = Validity))+stat_smooth(aes(x=TestSalAcc, y = ErrorRate, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarERtest

AcccovarRTtest <- ggplot(Exp7guess, aes(x = TestSalAcc, y = RT_io,group = Validity))+
  geom_jitter(aes(x = TestSalAcc, y = RT_io, color = Validity))+stat_smooth(aes(x=TestSalAcc, y = RT_io, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarRTtest



```

### only Questions

```{r}
anovaG_VS_Q <- aov(data = Exp7Aware, RT_io~Validity*Saliency*SaliencyAware)

pander(Anova(anovaG_VS_Q, type = "III"), style = "rmarkdown", caption = "ANCOVA results with questionnaire (type 3 SS)")
summary(anovaG_VS)


##For ErrorRate
anovaG_VSer_test <- aov(data = Exp7agg_GuessAware_ER, ErrorRate~Validity*Saliency*TestSalAcc)

pander(Anova(anovaG_VSer_test, type = "III"), style = "rmarkdown", caption = "ANCOVA results: ER with guessing accuracy (type 3 SS)")
summary(anovaG_VS)



AcccovarERtest <- ggplot(Exp7agg_GuessAware_ER, aes(x = TestSalAcc, y = ErrorRate,group = Validity))+
  geom_jitter(aes(x = TestSalAcc, y = ErrorRate, color = Validity))+stat_smooth(aes(x=TestSalAcc, y = ErrorRate, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarERtest

AcccovarRTtest <- ggplot(Exp7guess, aes(x = TestSalAcc, y = RT_io,group = Validity))+
  geom_jitter(aes(x = TestSalAcc, y = RT_io, color = Validity))+stat_smooth(aes(x=TestSalAcc, y = RT_io, color=Validity),method = "loess")+scale_color_manual(values = c("steelblue3","firebrick3"))+theme_classic()
AcccovarRTtest
```



## COMBINING

### Correltaion
```{r}
cor.test(Exp7Aware$TotalGuessingAcc, Exp7Aware$SaliencyAware, method = "pearson")

correlACC <- ggplot(Exp7guess, aes(x = SaliencyAware, y = TotalGuessingAcc))+
  geom_jitter(aes(x = SaliencyAware, y = TotalGuessingAcc), color = "seagreen")+
  stat_smooth(method = "lm", color = "seagreen")+theme_classic()+xlab("Accuracy score in Questions(Salient)")+ylab("Accuracy score in all guessing trials")+ggtitle("Correlation between both tests of awareness")
correlACC


cor.test(Exp7guess$LearnCA_Acc, Exp7guess$TestCA_Acc, method = "pearson")
correlguess <- ggplot(Exp7guess, aes(x = LearnCA_Acc, y = TestCA_Acc))+
  geom_jitter(aes(x = LearnCA_Acc, y = TestCA_Acc), color = "seagreen")+
  stat_smooth(method = "lm", color = "seagreen")+theme_classic()+xlab("Accuracy score in learn guess")+ylab("Accuracy score in test guessing trials")+ggtitle("Correlation between both types of guessing trials")
correlguess
```



## 4.  Using level of awareness in guessing and question trials as a factor

Now, let's focus only on the Salient guessing trials as well as questions. Given that the learn guessing trials are the main driving force in creating insight, a variable is created that is a factor of learnAwareness from guessing trials. So using median split, all the participans with more than 50% accuracy in the guessing learn trials are labelled as **"Learn Aware"** and the others are marked as **"Learn Unaware"**.

This is then compared with the participants' responses in the Questionnaire at the end of the experiment and checked if it matches with their guessing trials' performance.


```{r message=FALSE, warning=FALSE}

#if learnguess salient is high label those participants as learnAware. To be used to check if they correlate with the AwareQ responses of those participants

Exp7Aware$TotalSalAccuracy <- Exp7Aware$TestSalAcc + Exp7Aware$LearnSalAcc + Exp7Aware$SaliencyAware 
Exp7Aware$TotalSalAccuracy <- (Exp7Aware$TotalSalAccuracy/14)*100
Exp7Aware <- Exp7Aware %>%
  mutate(AwarenessLevel = ifelse(TotalSalAccuracy >= 80, "Aware", "Not Aware"))


```




### Using Awareness factors to the main aggregate df and evaluating the influence of insight in the interaction of validity and saliency

#### 1. Combining the awareness at the continginecy guessing trial level as well as the Questionnaire

To further evaluate how this awareness knowledge influences the interaction, a new factor was created *AwarenessMatch* that states the level of awareness the participant had and contains 4 factors:

1. Complete Awareness: They scored higher than chance in the learn guessing trials and answered both the awareness questions related to Salient distractors accurately.

2. Guess Awareness Not question: Show higher accuracy in learn guess salient trials but did not answer it accurately in the questionnaire

3. QuestionAwareness Not guess: Answered the salient distractor questions accurately but scored below chance level in the learn guess trials

4. No awareness: Did not have higher accuracy in the learn guess trials and no accuracy in the salient questions.


```{r }
##selecting pps who show both awareness in trials and questions


Exp7Aware <- Exp7Aware%>%
  dplyr::rename(LearnGuessTrials = LearnAwareness,
                SaliencyAwareQuestion = SaliencyAware,
                BothSalAwareQ = AwareQSal)
Exp7Aware <- Exp7Aware %>%
  mutate(AwarenessMatch = ifelse(LearnGuessTrials == "LearnAware" & BothSalAwareQ == 1, "CompleteAwareness", 
                                 ifelse(LearnGuessTrials == "LearnAware" & BothSalAwareQ == 0,"GuessAwareness Not Question",
                                        ifelse(LearnGuessTrials == "LearnNotaware" & BothSalAwareQ == 1, "QuestionAwareness Not guess",
                                               ifelse(LearnGuessTrials == "LearnNotaware" & BothSalAwareQ == 0,"NoAwareness",NA)))))


##### OLD FACTORS THAT WERE USED #####
# Exp7Aware <- Exp7Aware %>%
#   mutate(GuessSplit = ifelse(TotalAcc > 50, "high","low"))
# 
# Exp7Aware <- Exp7Aware %>%
#   group_by(participant)%>%
#   mutate(Awarelevel = ifelse(mean(TotalAcc) > 50, "Aware","less Aware"))
# 
# Exp7Aware <- Exp7Aware %>%
#   group_by(participant)%>%
#   mutate(LSAware = ifelse((Condition == "LearnGuess" & Saliency == "Saliency" & TotalAcc > 75), "Aware","UnAware"))
#table(Exp7Aware$LAware)/16 #around 21 people with 100% Acc and 49 people without


anova_VSg_o <- ezANOVA(data = Exp7Aware,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        between = .(AwarenessLevel),
        detailed = TRUE)
panderOptions('table.split.table',300)
pander(anova_VSg_o)

awareInterG <- ggplot(Exp7Aware, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~AwarenessLevel, labeller = label_wrap_gen(width = 10))+coord_cartesian(ylim = c(550,650))+xlab("Saliency")+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareInterG


#ggsave(filename = here("Figures","InteractionwithBothawareness.png"),awareInterG)
```

```{r}
mean_valEffectA_o <- ezStats(data = Exp7Aware,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        diff=.(Validity),
        between = .(AwarenessLevel),
        reverse_diff = TRUE)


pander(t.test(data = Exp7Aware, RT_io~Validity, subset = (Saliency == "Salient" & AwarenessMatch == "CompleteAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with full awareness")

pander(t.test(data = Exp7Aware, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "GuessAwareness Not Question"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only trials)")

pander(t.test(data = Exp7Aware, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "QuestionAwareness Not guess"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with partial awareness(only question)")

pander(t.test(data = Exp7Aware, RT_io~Validity, subset = (Saliency.x == "Salient" & AwarenessMatch == "NoAwareness"), paired = TRUE), style = "rmarkdown", caption = "t test for validity effect for salient trials for pp with no awareness")
```



The plot shows that when the participants have complete awareness there seems to be an interaction.

This pattern of interaction is also present for the participants with awareness at the questionnaire level but not at the contingency guessing level. Maybe this could be due to the fact that the questionnaire is presented at the end of the experiment which allowed for better insight.

The pattern is absent in participants who show no awareness and those with awareness only at the guessing trials levels show a pattern wherein the validity effect is larger in nonsalient (~23ms) compared to salient (~12ms).



#### 2. Only using awareness level at the questionnaire level

This variable (AwareQSal) is then included as a factor in the main aggregate df containing the validity and saliency effect for test trials. There is a significant interaction between validity and saliency similar to the standard analysis. While splitting the data for people with and without awareness, the people with awareness show a significant interaction between validity and saliency and those without awareness do not show any effect.

```{r awareanalysis, include=FALSE, warning=FALSE, message=FALSE}
# Exp7agg_A_fo <- merge(Exp7agg_fo,A_Summary,by="participant")
Exp7agg_AQ_o <- merge(Exp7agg_o,A_Summary,by="participant")

```

```{r awareanalysis0, message=FALSE, warning=FALSE, results='asis'}

##for outliers

Exp7agg_AQ_o$AwareQSal <- as.factor(Exp7agg_AQ_o$AwareQSal)
anova_VSAq_o <- ezANOVA(data = Exp7agg_AQ_o,
        dv = RT_io,
        wid = participant,
        within = .(Saliency,Validity),
        between = .(AwareQSal),
        detailed = TRUE)

pander(anova_VSAq_o, style = 'rmarkdown', caption = "ANOVA results with awareness: Outliers excluded",split.table = "Inf", missing = NA)


awareQInter <- ggplot(Exp7agg_AQ_o, aes(x=Saliency, y=RT_io,color = Validity))+
    geom_line(aes(group = Validity, linetype = Validity),size = 1,stat = "summary", fun = "mean",)+
    geom_point(stat = "summary", fun = "mean", aes(shape = Validity))+
  scale_color_manual(values = c("deepskyblue4","cadetblue3"))+facet_grid(.~AwareQSal)+coord_cartesian(ylim = c(550,650))+
  theme_classic()+ylab("Reaction Time in ms")+ggtitle("Interaction of Validity and Saliency \n between participants with and without awareness")
awareQInter

ggsave(filename = here("Figures","interactionbwAwareness_Questions.png"),awareQInter)

mean_aware_o <- ezStats(data = Exp7agg_AQ_o,
        dv = RT_io,
        wid = participant,
        within_full = .(Saliency,Validity),
        within = .(Saliency),
        between = .(AwareQSal),
        diff=.(Validity),
        reverse_diff = TRUE)

pander(mean_aware_o, style = "rmarkdown", title = "Validity effect(invalid-valid) (outliers excluded) for participants with contingency awareness of salient letters")

```
